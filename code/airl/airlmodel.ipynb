{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import PPO\n",
    "from imitation.algorithms.adversarial.airl import AIRL\n",
    "from imitation.util import util\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from imitation.util.util import make_vec_env\n",
    "from imitation.rewards.reward_nets import BasicShapedRewardNet\n",
    "from imitation.rewards.reward_nets import RewardNet\n",
    "from imitation.util.networks import RunningNorm\n",
    "from imitation.util import networks, util\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "th.manual_seed(SEED)\n",
    "if th.cuda.is_available():\n",
    "    th.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the true reward function's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 16\n",
    "num_actions = 4\n",
    "weights = np.random.uniform(0, 100, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37.45401188, 95.07143064, 73.19939418, 59.86584842, 15.60186404,\n",
       "       15.59945203,  5.80836122, 86.61761458, 60.11150117, 70.80725778,\n",
       "        2.05844943, 96.99098522, 83.24426408, 21.23391107, 18.18249672,\n",
       "       18.34045099])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self, num_features: int = num_features, num_actions: int = num_actions, weights=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        # Observation space is discrete \n",
    "        self.observation_space = spaces.Discrete(num_features)\n",
    "        self.action_space = spaces.Discrete(num_actions) \n",
    "\n",
    "        # Define transition matrix: shape (num_features, num_actions, num_features)\n",
    "        self.transition_matrix = np.random.rand(num_features, num_actions, num_features)\n",
    "        self.transition_matrix /= self.transition_matrix.sum(axis=2, keepdims=True)  # Normalize to ensure probabilities\n",
    "\n",
    "        self.state = None\n",
    "        self.max_steps = 1000\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Initialize weights for reward calculation and normalize them\n",
    "        self.weights = weights\n",
    "        self.weights = self.weights\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed, options=options)\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        # Sample a discrete state (integer)\n",
    "        self.state = np.random.choice(self.num_features)\n",
    "        self.current_step = 0\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Calculate reward based on the normalized weights for the current state\n",
    "        reward = self.weights[self.state]\n",
    "\n",
    "        next_state_probs = self.transition_matrix[self.state, action]\n",
    "        next_state = np.random.choice(range(self.num_features), p=next_state_probs)\n",
    "\n",
    "        if next_state != self.state:\n",
    "            reward += 0.1  # Small bonus for transitioning to a different state\n",
    "\n",
    "        # Update the state to the new discrete state\n",
    "        self.state = next_state\n",
    "\n",
    "        # Increment step counter\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Check if the episode is done based on the step limit\n",
    "        done = self.current_step >= self.max_steps\n",
    "        truncated = False\n",
    "\n",
    "        info = {\"obs\": self.state, \"rews\": reward}\n",
    "\n",
    "        # Return the next state (as a discrete integer), the reward, and whether the episode is done\n",
    "        return self.state, reward, done, truncated, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the custom environment to use OpenAI's Gym API (intializes the environment with the true reward function's weights to determine state->action behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register(id='CustomEnv-v0', entry_point=lambda: CustomEnv(weights=weights), max_episode_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vectorized environment for efficient training (train multiple instances of same environment simultaneously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "venv = util.make_vec_env(\"CustomEnv-v0\", rng=np.random.default_rng(SEED), n_envs=4, post_wrappers=[lambda env, _: RolloutInfoWrapper(env)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalize a PPO agent to learn the environment over 10000 steps using the \"MlpPolicy\"\n",
    "PPO (Proximal Policy Optimization):\n",
    "    1. collects experiences (states, actions, rewards over some episodes)\n",
    "    2. try to find advantageous actions\n",
    "    3. Update policy\n",
    "\n",
    "Using the trained policy, collect data of the trajectories (interactions of the trained agent with the environment from some episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamhuang/anaconda3/envs/tobin/lib/python3.8/site-packages/imitation/data/types.py:279: UserWarning: tried to wrap <class 'numpy.int64'> as an observation\n",
      "  warnings.warn(f\"tried to wrap {type(obs)} as an observation\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | 4.75e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 15259    |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 8192     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | 4.72e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 6674         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002125399 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -6.93e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.93e+05     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000674    |\n",
      "|    value_loss           | 4.72e+05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | 4.71e+03       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 5825           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 24576          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000108207925 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.39          |\n",
      "|    explained_variance   | -2.74e-06      |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 2.13e+05       |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | -0.000465      |\n",
      "|    value_loss           | 4.61e+05       |\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "expert_policy = PPO('MlpPolicy', venv, verbose=1, seed=SEED)\n",
    "expert_policy.learn(total_timesteps=20000)\n",
    "\n",
    "# Collect rollouts\n",
    "rollouts = rollout.rollout(\n",
    "    expert_policy,\n",
    "    venv,\n",
    "    rollout.make_sample_until(min_episodes=500),\n",
    "    rng=np.random.default_rng(SEED),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rollouts = pd.DataFrame(rollouts)\n",
    "save_rollouts.to_csv(\"rollouts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Simple Linear Model Reward Function to Learn During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRewardNet(RewardNet):\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super().__init__(observation_space, action_space)\n",
    "\n",
    "        # Handle different types of observation spaces\n",
    "        if isinstance(observation_space, spaces.Box):\n",
    "            self.state_dim = observation_space.shape[0]\n",
    "        elif isinstance(observation_space, spaces.Discrete):\n",
    "            self.state_dim = observation_space.n  # Number of possible discrete states\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported observation space: {type(observation_space)}\")\n",
    "        \n",
    "        # Define a linear layer that maps from state (one-hot encoded) to reward\n",
    "        self.linear = nn.Linear(self.state_dim, 1)  \n",
    "        init.xavier_uniform_(self.linear.weight)\n",
    "        init.constant_(self.linear.bias, 0.0)  \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        state: th.Tensor,\n",
    "        action: th.Tensor,  \n",
    "        next_state: th.Tensor,\n",
    "        done: th.Tensor,\n",
    "    ) -> th.Tensor:\n",
    "        batch_size = state.shape[0]\n",
    "        # print(f\"BATCH SIZE = {batch_size}\")\n",
    "        # print(f\"STATE SHAPE = {state.shape}\")\n",
    "        reward = self.linear(state)\n",
    "        # print(f\"REWARD SHAPE = {reward.shape}\")\n",
    "\n",
    "\n",
    "        reward = reward.squeeze(-1)\n",
    "\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imitation library's nonlinear model\n",
    "reward_net = BasicShapedRewardNet(\n",
    "    observation_space=venv.observation_space,\n",
    "    action_space=venv.action_space,\n",
    "    normalize_input_layer=RunningNorm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_net = LinearRewardNet(\n",
    "    observation_space=venv.observation_space,\n",
    "    action_space=venv.action_space,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize AIRL to be trained on the environment, with the expert data, and the same MlpPolicy as the generator to train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = PPO(\n",
    "    env=venv,\n",
    "    policy=MlpPolicy,\n",
    "    batch_size=64,\n",
    "    ent_coef=0.0,\n",
    "    learning_rate=0.0005,\n",
    "    gamma=0.95,\n",
    "    clip_range=0.1,\n",
    "    vf_coef=0.1,\n",
    "    n_epochs=5,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "airl_trainer = AIRL(\n",
    "    venv=venv,\n",
    "    demonstrations=rollouts,\n",
    "    demo_batch_size=2048,\n",
    "    gen_replay_buffer_capacity=512,\n",
    "    gen_algo= expert_policy,\n",
    "    reward_net=reward_net,\n",
    "    n_disc_updates_per_round=16,\n",
    "    gen_train_timesteps=20000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| raw/                        |          |\n",
      "|    gen/rollout/ep_len_mean  | 100      |\n",
      "|    gen/rollout/ep_rew_mean  | 4.78e+03 |\n",
      "|    gen/time/fps             | 10090    |\n",
      "|    gen/time/iterations      | 1        |\n",
      "|    gen/time/time_elapsed    | 0        |\n",
      "|    gen/time/total_timesteps | 32768    |\n",
      "------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.78e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 10.8        |\n",
      "|    gen/time/fps                    | 5588        |\n",
      "|    gen/time/iterations             | 2           |\n",
      "|    gen/time/time_elapsed           | 2           |\n",
      "|    gen/time/total_timesteps        | 40960       |\n",
      "|    gen/train/approx_kl             | 0.010390077 |\n",
      "|    gen/train/clip_fraction         | 0.0578      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.38       |\n",
      "|    gen/train/explained_variance    | 3.46e-06    |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 3.68        |\n",
      "|    gen/train/n_updates             | 40          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00533    |\n",
      "|    gen/train/value_loss            | 26.5        |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 10.7        |\n",
      "|    gen/time/fps                    | 4936        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 4           |\n",
      "|    gen/time/total_timesteps        | 49152       |\n",
      "|    gen/train/approx_kl             | 0.009072471 |\n",
      "|    gen/train/clip_fraction         | 0.0199      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.37       |\n",
      "|    gen/train/explained_variance    | 0.0135      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 3.11        |\n",
      "|    gen/train/n_updates             | 50          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00386    |\n",
      "|    gen/train/value_loss            | 12.8        |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.953    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.954    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.47     |\n",
      "|    disc/disc_loss                   | 0.954    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.953    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.956    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.957    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.953    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.959    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.952    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.951    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.956    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.949    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.951    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.953    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.943    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.946    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.952    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.76e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | 10.7     |\n",
      "|    gen/time/fps                     | 6.87e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 4.1e+04  |\n",
      "|    gen/train/approx_kl              | 0.00992  |\n",
      "|    gen/train/clip_fraction          | 0.0384   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -1.37    |\n",
      "|    gen/train/explained_variance     | 0.0104   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 3.51     |\n",
      "|    gen/train/n_updates              | 50       |\n",
      "|    gen/train/policy_gradient_loss   | -0.0047  |\n",
      "|    gen/train/value_loss             | 15.3     |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:   5%|â–Œ         | 1/20 [00:06<02:06,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.64e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 11.7        |\n",
      "|    gen/time/fps                    | 10912       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 57344       |\n",
      "|    gen/train/approx_kl             | 0.010310242 |\n",
      "|    gen/train/clip_fraction         | 0.0376      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.36       |\n",
      "|    gen/train/explained_variance    | 0.0176      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 3.74        |\n",
      "|    gen/train/n_updates             | 60          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00491    |\n",
      "|    gen/train/value_loss            | 6.56        |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 7.8          |\n",
      "|    gen/time/fps                    | 5942         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 2            |\n",
      "|    gen/time/total_timesteps        | 65536        |\n",
      "|    gen/train/approx_kl             | 0.0074425386 |\n",
      "|    gen/train/clip_fraction         | 0.0225       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -1.34        |\n",
      "|    gen/train/explained_variance    | 0.0152       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 2.99         |\n",
      "|    gen/train/n_updates             | 70           |\n",
      "|    gen/train/policy_gradient_loss  | -0.00307     |\n",
      "|    gen/train/value_loss            | 5.81         |\n",
      "-----------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| raw/                               |            |\n",
      "|    gen/rollout/ep_len_mean         | 100        |\n",
      "|    gen/rollout/ep_rew_mean         | 4.72e+03   |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 7.5        |\n",
      "|    gen/time/fps                    | 5190       |\n",
      "|    gen/time/iterations             | 3          |\n",
      "|    gen/time/time_elapsed           | 4          |\n",
      "|    gen/time/total_timesteps        | 73728      |\n",
      "|    gen/train/approx_kl             | 0.00920598 |\n",
      "|    gen/train/clip_fraction         | 0.0509     |\n",
      "|    gen/train/clip_range            | 0.2        |\n",
      "|    gen/train/entropy_loss          | -1.34      |\n",
      "|    gen/train/explained_variance    | 0.0176     |\n",
      "|    gen/train/learning_rate         | 0.0003     |\n",
      "|    gen/train/loss                  | 1.52       |\n",
      "|    gen/train/n_updates             | 80         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00557   |\n",
      "|    gen/train/value_loss            | 4.07       |\n",
      "---------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.938    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.939    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.932    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.936    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.929    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.931    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.932    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.922    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.93     |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.928    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.931    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.5      |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0        |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.928    |\n",
      "|    disc/disc_proportion_expert_pred | 1        |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.517    |\n",
      "|    disc/disc_acc_expert             | 0.984    |\n",
      "|    disc/disc_acc_gen                | 0.0503   |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.916    |\n",
      "|    disc/disc_proportion_expert_pred | 0.967    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.513    |\n",
      "|    disc/disc_acc_expert             | 0.984    |\n",
      "|    disc/disc_acc_gen                | 0.0425   |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.926    |\n",
      "|    disc/disc_proportion_expert_pred | 0.971    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.511    |\n",
      "|    disc/disc_acc_expert             | 0.978    |\n",
      "|    disc/disc_acc_gen                | 0.0439   |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.931    |\n",
      "|    disc/disc_proportion_expert_pred | 0.967    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.516    |\n",
      "|    disc/disc_acc_expert             | 0.987    |\n",
      "|    disc/disc_acc_gen                | 0.0439   |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.928    |\n",
      "|    disc/disc_proportion_expert_pred | 0.972    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.504    |\n",
      "|    disc/disc_acc_expert             | 0.996    |\n",
      "|    disc/disc_acc_gen                | 0.0113   |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.93     |\n",
      "|    disc/disc_proportion_expert_pred | 0.992    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 2        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.69e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | 9.01     |\n",
      "|    gen/time/fps                     | 7.35e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 6.55e+04 |\n",
      "|    gen/train/approx_kl              | 0.00927  |\n",
      "|    gen/train/clip_fraction          | 0.0432   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -1.34    |\n",
      "|    gen/train/explained_variance     | 0.019    |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 1.76     |\n",
      "|    gen/train/n_updates              | 80       |\n",
      "|    gen/train/policy_gradient_loss   | -0.00476 |\n",
      "|    gen/train/value_loss             | 4.35     |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  10%|â–ˆ         | 2/20 [00:13<01:57,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.76e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 7.81        |\n",
      "|    gen/time/fps                    | 10974       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 81920       |\n",
      "|    gen/train/approx_kl             | 0.011175511 |\n",
      "|    gen/train/clip_fraction         | 0.0562      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.34       |\n",
      "|    gen/train/explained_variance    | 0.0241      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.781       |\n",
      "|    gen/train/n_updates             | 90          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00565    |\n",
      "|    gen/train/value_loss            | 3.17        |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.72e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 5.11        |\n",
      "|    gen/time/fps                    | 5808        |\n",
      "|    gen/time/iterations             | 2           |\n",
      "|    gen/time/time_elapsed           | 2           |\n",
      "|    gen/time/total_timesteps        | 90112       |\n",
      "|    gen/train/approx_kl             | 0.010036467 |\n",
      "|    gen/train/clip_fraction         | 0.0588      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.32       |\n",
      "|    gen/train/explained_variance    | 0.0273      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 1.19        |\n",
      "|    gen/train/n_updates             | 100         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00509    |\n",
      "|    gen/train/value_loss            | 3.07        |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.74e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 4.3         |\n",
      "|    gen/time/fps                    | 4410        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 5           |\n",
      "|    gen/time/total_timesteps        | 98304       |\n",
      "|    gen/train/approx_kl             | 0.009454497 |\n",
      "|    gen/train/clip_fraction         | 0.0754      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.29       |\n",
      "|    gen/train/explained_variance    | 0.043       |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 1.02        |\n",
      "|    gen/train/n_updates             | 110         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00614    |\n",
      "|    gen/train/value_loss            | 2.39        |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.507    |\n",
      "|    disc/disc_acc_expert             | 0.983    |\n",
      "|    disc/disc_acc_gen                | 0.0308   |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.923    |\n",
      "|    disc/disc_proportion_expert_pred | 0.976    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.51     |\n",
      "|    disc/disc_acc_expert             | 0.986    |\n",
      "|    disc/disc_acc_gen                | 0.0347   |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.917    |\n",
      "|    disc/disc_proportion_expert_pred | 0.976    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.506    |\n",
      "|    disc/disc_acc_expert             | 0.983    |\n",
      "|    disc/disc_acc_gen                | 0.0298   |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.925    |\n",
      "|    disc/disc_proportion_expert_pred | 0.977    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.509    |\n",
      "|    disc/disc_acc_expert             | 0.985    |\n",
      "|    disc/disc_acc_gen                | 0.0322   |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.911    |\n",
      "|    disc/disc_proportion_expert_pred | 0.976    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.51     |\n",
      "|    disc/disc_acc_expert             | 0.989    |\n",
      "|    disc/disc_acc_gen                | 0.0312   |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.919    |\n",
      "|    disc/disc_proportion_expert_pred | 0.979    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.503    |\n",
      "|    disc/disc_acc_expert             | 0.981    |\n",
      "|    disc/disc_acc_gen                | 0.0244   |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.933    |\n",
      "|    disc/disc_proportion_expert_pred | 0.978    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.508    |\n",
      "|    disc/disc_acc_expert             | 0.984    |\n",
      "|    disc/disc_acc_gen                | 0.0327   |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.913    |\n",
      "|    disc/disc_proportion_expert_pred | 0.976    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.506    |\n",
      "|    disc/disc_acc_expert             | 0.985    |\n",
      "|    disc/disc_acc_gen                | 0.0278   |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.929    |\n",
      "|    disc/disc_proportion_expert_pred | 0.979    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.509    |\n",
      "|    disc/disc_acc_expert             | 0.987    |\n",
      "|    disc/disc_acc_gen                | 0.0317   |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.909    |\n",
      "|    disc/disc_proportion_expert_pred | 0.978    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.506    |\n",
      "|    disc/disc_acc_expert             | 0.985    |\n",
      "|    disc/disc_acc_gen                | 0.0273   |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.912    |\n",
      "|    disc/disc_proportion_expert_pred | 0.979    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.509    |\n",
      "|    disc/disc_acc_expert             | 0.986    |\n",
      "|    disc/disc_acc_gen                | 0.0322   |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.913    |\n",
      "|    disc/disc_proportion_expert_pred | 0.977    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.51     |\n",
      "|    disc/disc_acc_expert             | 0.986    |\n",
      "|    disc/disc_acc_gen                | 0.0342   |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.914    |\n",
      "|    disc/disc_proportion_expert_pred | 0.976    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.504    |\n",
      "|    disc/disc_acc_expert             | 0.985    |\n",
      "|    disc/disc_acc_gen                | 0.0229   |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.926    |\n",
      "|    disc/disc_proportion_expert_pred | 0.981    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.507    |\n",
      "|    disc/disc_acc_expert             | 0.985    |\n",
      "|    disc/disc_acc_gen                | 0.0293   |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.919    |\n",
      "|    disc/disc_proportion_expert_pred | 0.978    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.508    |\n",
      "|    disc/disc_acc_expert             | 0.988    |\n",
      "|    disc/disc_acc_gen                | 0.0283   |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.911    |\n",
      "|    disc/disc_proportion_expert_pred | 0.98     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.504    |\n",
      "|    disc/disc_acc_expert             | 0.982    |\n",
      "|    disc/disc_acc_gen                | 0.0264   |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.911    |\n",
      "|    disc/disc_proportion_expert_pred | 0.978    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.507    |\n",
      "|    disc/disc_acc_expert             | 0.985    |\n",
      "|    disc/disc_acc_gen                | 0.0298   |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.918    |\n",
      "|    disc/disc_proportion_expert_pred | 0.978    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 3        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.74e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | 5.74     |\n",
      "|    gen/time/fps                     | 7.06e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.33     |\n",
      "|    gen/time/total_timesteps         | 9.01e+04 |\n",
      "|    gen/train/approx_kl              | 0.0101   |\n",
      "|    gen/train/clip_fraction          | 0.0679   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -1.29    |\n",
      "|    gen/train/explained_variance     | 0.0372   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 1.01     |\n",
      "|    gen/train/n_updates              | 110      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00553 |\n",
      "|    gen/train/value_loss             | 2.45     |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  15%|â–ˆâ–Œ        | 3/20 [00:20<01:56,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.73e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 4.8         |\n",
      "|    gen/time/fps                    | 11041       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 106496      |\n",
      "|    gen/train/approx_kl             | 0.010782806 |\n",
      "|    gen/train/clip_fraction         | 0.0694      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.26       |\n",
      "|    gen/train/explained_variance    | 0.0414      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.822       |\n",
      "|    gen/train/n_updates             | 120         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00535    |\n",
      "|    gen/train/value_loss            | 1.9         |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 2.49        |\n",
      "|    gen/time/fps                    | 5864        |\n",
      "|    gen/time/iterations             | 2           |\n",
      "|    gen/time/time_elapsed           | 2           |\n",
      "|    gen/time/total_timesteps        | 114688      |\n",
      "|    gen/train/approx_kl             | 0.011859209 |\n",
      "|    gen/train/clip_fraction         | 0.0976      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.23       |\n",
      "|    gen/train/explained_variance    | 0.0468      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.817       |\n",
      "|    gen/train/n_updates             | 130         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00771    |\n",
      "|    gen/train/value_loss            | 1.85        |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.74e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 1.34        |\n",
      "|    gen/time/fps                    | 5050        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 4           |\n",
      "|    gen/time/total_timesteps        | 122880      |\n",
      "|    gen/train/approx_kl             | 0.011025439 |\n",
      "|    gen/train/clip_fraction         | 0.072       |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.23       |\n",
      "|    gen/train/explained_variance    | 0.0551      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.798       |\n",
      "|    gen/train/n_updates             | 140         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00586    |\n",
      "|    gen/train/value_loss            | 1.74        |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.517    |\n",
      "|    disc/disc_acc_expert             | 0.984    |\n",
      "|    disc/disc_acc_gen                | 0.0508   |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.869    |\n",
      "|    disc/disc_proportion_expert_pred | 0.967    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.514    |\n",
      "|    disc/disc_acc_expert             | 0.988    |\n",
      "|    disc/disc_acc_gen                | 0.0405   |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.874    |\n",
      "|    disc/disc_proportion_expert_pred | 0.974    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.519    |\n",
      "|    disc/disc_acc_expert             | 0.986    |\n",
      "|    disc/disc_acc_gen                | 0.0508   |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.88     |\n",
      "|    disc/disc_proportion_expert_pred | 0.968    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.515    |\n",
      "|    disc/disc_acc_expert             | 0.985    |\n",
      "|    disc/disc_acc_gen                | 0.0454   |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.874    |\n",
      "|    disc/disc_proportion_expert_pred | 0.97     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.513    |\n",
      "|    disc/disc_acc_expert             | 0.98     |\n",
      "|    disc/disc_acc_gen                | 0.0464   |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.871    |\n",
      "|    disc/disc_proportion_expert_pred | 0.967    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.519    |\n",
      "|    disc/disc_acc_expert             | 0.984    |\n",
      "|    disc/disc_acc_gen                | 0.0532   |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.879    |\n",
      "|    disc/disc_proportion_expert_pred | 0.965    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.515    |\n",
      "|    disc/disc_acc_expert             | 0.987    |\n",
      "|    disc/disc_acc_gen                | 0.043    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.881    |\n",
      "|    disc/disc_proportion_expert_pred | 0.972    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.514    |\n",
      "|    disc/disc_acc_expert             | 0.987    |\n",
      "|    disc/disc_acc_gen                | 0.041    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.875    |\n",
      "|    disc/disc_proportion_expert_pred | 0.973    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.515    |\n",
      "|    disc/disc_acc_expert             | 0.986    |\n",
      "|    disc/disc_acc_gen                | 0.0444   |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.868    |\n",
      "|    disc/disc_proportion_expert_pred | 0.971    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.516    |\n",
      "|    disc/disc_acc_expert             | 0.982    |\n",
      "|    disc/disc_acc_gen                | 0.0488   |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.88     |\n",
      "|    disc/disc_proportion_expert_pred | 0.967    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.515    |\n",
      "|    disc/disc_acc_expert             | 0.982    |\n",
      "|    disc/disc_acc_gen                | 0.0474   |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.873    |\n",
      "|    disc/disc_proportion_expert_pred | 0.968    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.52     |\n",
      "|    disc/disc_acc_expert             | 0.986    |\n",
      "|    disc/disc_acc_gen                | 0.0542   |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.866    |\n",
      "|    disc/disc_proportion_expert_pred | 0.966    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.52     |\n",
      "|    disc/disc_acc_expert             | 0.989    |\n",
      "|    disc/disc_acc_gen                | 0.0503   |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.858    |\n",
      "|    disc/disc_proportion_expert_pred | 0.969    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.52     |\n",
      "|    disc/disc_acc_expert             | 0.987    |\n",
      "|    disc/disc_acc_gen                | 0.0527   |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.866    |\n",
      "|    disc/disc_proportion_expert_pred | 0.967    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.516    |\n",
      "|    disc/disc_acc_expert             | 0.991    |\n",
      "|    disc/disc_acc_gen                | 0.041    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.866    |\n",
      "|    disc/disc_proportion_expert_pred | 0.975    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.515    |\n",
      "|    disc/disc_acc_expert             | 0.981    |\n",
      "|    disc/disc_acc_gen                | 0.0483   |\n",
      "|    disc/disc_entropy                | 0.495    |\n",
      "|    disc/disc_loss                   | 0.875    |\n",
      "|    disc/disc_proportion_expert_pred | 0.966    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.516    |\n",
      "|    disc/disc_acc_expert             | 0.985    |\n",
      "|    disc/disc_acc_gen                | 0.0474   |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.872    |\n",
      "|    disc/disc_proportion_expert_pred | 0.969    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 4        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.73e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | 2.88     |\n",
      "|    gen/time/fps                     | 7.32e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 1.15e+05 |\n",
      "|    gen/train/approx_kl              | 0.0106   |\n",
      "|    gen/train/clip_fraction          | 0.0794   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -1.23    |\n",
      "|    gen/train/explained_variance     | 0.0558   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.818    |\n",
      "|    gen/train/n_updates              | 140      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00642 |\n",
      "|    gen/train/value_loss             | 1.66     |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  20%|â–ˆâ–ˆ        | 4/20 [00:26<01:46,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.73e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | 1.79        |\n",
      "|    gen/time/fps                    | 11078       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 131072      |\n",
      "|    gen/train/approx_kl             | 0.008802869 |\n",
      "|    gen/train/clip_fraction         | 0.0687      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.22       |\n",
      "|    gen/train/explained_variance    | 0.0656      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.839       |\n",
      "|    gen/train/n_updates             | 150         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00568    |\n",
      "|    gen/train/value_loss            | 1.38        |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.72e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -1.16       |\n",
      "|    gen/time/fps                    | 5868        |\n",
      "|    gen/time/iterations             | 2           |\n",
      "|    gen/time/time_elapsed           | 2           |\n",
      "|    gen/time/total_timesteps        | 139264      |\n",
      "|    gen/train/approx_kl             | 0.010121513 |\n",
      "|    gen/train/clip_fraction         | 0.0693      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.19       |\n",
      "|    gen/train/explained_variance    | 0.0605      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 1.01        |\n",
      "|    gen/train/n_updates             | 160         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00563    |\n",
      "|    gen/train/value_loss            | 1.57        |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.74e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -1.27       |\n",
      "|    gen/time/fps                    | 5119        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 4           |\n",
      "|    gen/time/total_timesteps        | 147456      |\n",
      "|    gen/train/approx_kl             | 0.009305462 |\n",
      "|    gen/train/clip_fraction         | 0.0613      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.15       |\n",
      "|    gen/train/explained_variance    | 0.0671      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.519       |\n",
      "|    gen/train/n_updates             | 170         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00444    |\n",
      "|    gen/train/value_loss            | 1.25        |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.525    |\n",
      "|    disc/disc_acc_expert             | 0.968    |\n",
      "|    disc/disc_acc_gen                | 0.082    |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.858    |\n",
      "|    disc/disc_proportion_expert_pred | 0.943    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.531    |\n",
      "|    disc/disc_acc_expert             | 0.964    |\n",
      "|    disc/disc_acc_gen                | 0.0977   |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.845    |\n",
      "|    disc/disc_proportion_expert_pred | 0.933    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.528    |\n",
      "|    disc/disc_acc_expert             | 0.969    |\n",
      "|    disc/disc_acc_gen                | 0.0859   |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.864    |\n",
      "|    disc/disc_proportion_expert_pred | 0.942    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.972    |\n",
      "|    disc/disc_acc_gen                | 0.0942   |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.861    |\n",
      "|    disc/disc_proportion_expert_pred | 0.939    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.968    |\n",
      "|    disc/disc_acc_gen                | 0.102    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.857    |\n",
      "|    disc/disc_proportion_expert_pred | 0.933    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.531    |\n",
      "|    disc/disc_acc_expert             | 0.973    |\n",
      "|    disc/disc_acc_gen                | 0.0898   |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.861    |\n",
      "|    disc/disc_proportion_expert_pred | 0.941    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.531    |\n",
      "|    disc/disc_acc_expert             | 0.969    |\n",
      "|    disc/disc_acc_gen                | 0.0933   |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.856    |\n",
      "|    disc/disc_proportion_expert_pred | 0.938    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.971    |\n",
      "|    disc/disc_acc_gen                | 0.0991   |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.842    |\n",
      "|    disc/disc_proportion_expert_pred | 0.936    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.523    |\n",
      "|    disc/disc_acc_expert             | 0.965    |\n",
      "|    disc/disc_acc_gen                | 0.0811   |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.856    |\n",
      "|    disc/disc_proportion_expert_pred | 0.942    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.977    |\n",
      "|    disc/disc_acc_gen                | 0.0884   |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.859    |\n",
      "|    disc/disc_proportion_expert_pred | 0.944    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.973    |\n",
      "|    disc/disc_acc_gen                | 0.0967   |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.855    |\n",
      "|    disc/disc_proportion_expert_pred | 0.938    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.532    |\n",
      "|    disc/disc_acc_expert             | 0.979    |\n",
      "|    disc/disc_acc_gen                | 0.0854   |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.859    |\n",
      "|    disc/disc_proportion_expert_pred | 0.947    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.977    |\n",
      "|    disc/disc_acc_gen                | 0.0894   |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.849    |\n",
      "|    disc/disc_proportion_expert_pred | 0.944    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.521    |\n",
      "|    disc/disc_acc_expert             | 0.964    |\n",
      "|    disc/disc_acc_gen                | 0.0791   |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.847    |\n",
      "|    disc/disc_proportion_expert_pred | 0.942    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.527    |\n",
      "|    disc/disc_acc_expert             | 0.963    |\n",
      "|    disc/disc_acc_gen                | 0.0903   |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.856    |\n",
      "|    disc/disc_proportion_expert_pred | 0.937    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.524    |\n",
      "|    disc/disc_acc_expert             | 0.967    |\n",
      "|    disc/disc_acc_gen                | 0.0815   |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.855    |\n",
      "|    disc/disc_proportion_expert_pred | 0.943    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.53     |\n",
      "|    disc/disc_acc_expert             | 0.97     |\n",
      "|    disc/disc_acc_gen                | 0.0897   |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.855    |\n",
      "|    disc/disc_proportion_expert_pred | 0.94     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 5        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.73e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -0.212   |\n",
      "|    gen/time/fps                     | 7.36e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 1.39e+05 |\n",
      "|    gen/train/approx_kl              | 0.00938  |\n",
      "|    gen/train/clip_fraction          | 0.0666   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -1.16    |\n",
      "|    gen/train/explained_variance     | 0.0645   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.689    |\n",
      "|    gen/train/n_updates              | 170      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00504 |\n",
      "|    gen/train/value_loss             | 1.36     |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:33<01:38,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.69e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -0.958      |\n",
      "|    gen/time/fps                    | 11192       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 155648      |\n",
      "|    gen/train/approx_kl             | 0.008709215 |\n",
      "|    gen/train/clip_fraction         | 0.0692      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.13       |\n",
      "|    gen/train/explained_variance    | 0.0659      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.54        |\n",
      "|    gen/train/n_updates             | 180         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00506    |\n",
      "|    gen/train/value_loss            | 1.25        |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.66e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -3.19       |\n",
      "|    gen/time/fps                    | 5729        |\n",
      "|    gen/time/iterations             | 2           |\n",
      "|    gen/time/time_elapsed           | 2           |\n",
      "|    gen/time/total_timesteps        | 163840      |\n",
      "|    gen/train/approx_kl             | 0.006984641 |\n",
      "|    gen/train/clip_fraction         | 0.0518      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.1        |\n",
      "|    gen/train/explained_variance    | 0.0678      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.452       |\n",
      "|    gen/train/n_updates             | 190         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00346    |\n",
      "|    gen/train/value_loss            | 1.11        |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -4.19       |\n",
      "|    gen/time/fps                    | 5010        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 4           |\n",
      "|    gen/time/total_timesteps        | 172032      |\n",
      "|    gen/train/approx_kl             | 0.010054383 |\n",
      "|    gen/train/clip_fraction         | 0.0894      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.08       |\n",
      "|    gen/train/explained_variance    | 0.0743      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.499       |\n",
      "|    gen/train/n_updates             | 200         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00713    |\n",
      "|    gen/train/value_loss            | 1.08        |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.522    |\n",
      "|    disc/disc_acc_expert             | 0.971    |\n",
      "|    disc/disc_acc_gen                | 0.0728   |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.823    |\n",
      "|    disc/disc_proportion_expert_pred | 0.949    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.527    |\n",
      "|    disc/disc_acc_expert             | 0.976    |\n",
      "|    disc/disc_acc_gen                | 0.0786   |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.812    |\n",
      "|    disc/disc_proportion_expert_pred | 0.948    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.519    |\n",
      "|    disc/disc_acc_expert             | 0.967    |\n",
      "|    disc/disc_acc_gen                | 0.0708   |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.818    |\n",
      "|    disc/disc_proportion_expert_pred | 0.948    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.517    |\n",
      "|    disc/disc_acc_expert             | 0.964    |\n",
      "|    disc/disc_acc_gen                | 0.0693   |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.818    |\n",
      "|    disc/disc_proportion_expert_pred | 0.947    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.521    |\n",
      "|    disc/disc_acc_expert             | 0.966    |\n",
      "|    disc/disc_acc_gen                | 0.0762   |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.82     |\n",
      "|    disc/disc_proportion_expert_pred | 0.945    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.525    |\n",
      "|    disc/disc_acc_expert             | 0.976    |\n",
      "|    disc/disc_acc_gen                | 0.0747   |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.803    |\n",
      "|    disc/disc_proportion_expert_pred | 0.951    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.519    |\n",
      "|    disc/disc_acc_expert             | 0.962    |\n",
      "|    disc/disc_acc_gen                | 0.0767   |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.81     |\n",
      "|    disc/disc_proportion_expert_pred | 0.943    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.522    |\n",
      "|    disc/disc_acc_expert             | 0.97     |\n",
      "|    disc/disc_acc_gen                | 0.0747   |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.814    |\n",
      "|    disc/disc_proportion_expert_pred | 0.948    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.524    |\n",
      "|    disc/disc_acc_expert             | 0.963    |\n",
      "|    disc/disc_acc_gen                | 0.0845   |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.81     |\n",
      "|    disc/disc_proportion_expert_pred | 0.939    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.514    |\n",
      "|    disc/disc_acc_expert             | 0.967    |\n",
      "|    disc/disc_acc_gen                | 0.062    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.815    |\n",
      "|    disc/disc_proportion_expert_pred | 0.952    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.521    |\n",
      "|    disc/disc_acc_expert             | 0.97     |\n",
      "|    disc/disc_acc_gen                | 0.0713   |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.82     |\n",
      "|    disc/disc_proportion_expert_pred | 0.949    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.954    |\n",
      "|    disc/disc_acc_gen                | 0.117    |\n",
      "|    disc/disc_entropy                | 0.493    |\n",
      "|    disc/disc_loss                   | 0.806    |\n",
      "|    disc/disc_proportion_expert_pred | 0.918    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.518    |\n",
      "|    disc/disc_acc_expert             | 0.937    |\n",
      "|    disc/disc_acc_gen                | 0.0981   |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.811    |\n",
      "|    disc/disc_proportion_expert_pred | 0.919    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.539    |\n",
      "|    disc/disc_acc_expert             | 0.956    |\n",
      "|    disc/disc_acc_gen                | 0.121    |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.804    |\n",
      "|    disc/disc_proportion_expert_pred | 0.917    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.529    |\n",
      "|    disc/disc_acc_expert             | 0.958    |\n",
      "|    disc/disc_acc_gen                | 0.0991   |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.808    |\n",
      "|    disc/disc_proportion_expert_pred | 0.929    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.953    |\n",
      "|    disc/disc_acc_gen                | 0.115    |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.805    |\n",
      "|    disc/disc_proportion_expert_pred | 0.919    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.524    |\n",
      "|    disc/disc_acc_expert             | 0.963    |\n",
      "|    disc/disc_acc_gen                | 0.0851   |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.812    |\n",
      "|    disc/disc_proportion_expert_pred | 0.939    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 6        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.69e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -2.78    |\n",
      "|    gen/time/fps                     | 7.31e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 1.64e+05 |\n",
      "|    gen/train/approx_kl              | 0.00846  |\n",
      "|    gen/train/clip_fraction          | 0.0658   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -1.08    |\n",
      "|    gen/train/explained_variance     | 0.0777   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.516    |\n",
      "|    gen/train/n_updates              | 200      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00499 |\n",
      "|    gen/train/value_loss             | 1.1      |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:40<01:34,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.73e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -3.97       |\n",
      "|    gen/time/fps                    | 11279       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 180224      |\n",
      "|    gen/train/approx_kl             | 0.008354871 |\n",
      "|    gen/train/clip_fraction         | 0.0562      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.06       |\n",
      "|    gen/train/explained_variance    | 0.091       |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.597       |\n",
      "|    gen/train/n_updates             | 210         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00436    |\n",
      "|    gen/train/value_loss            | 1.1         |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.68e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -5.86        |\n",
      "|    gen/time/fps                    | 6000         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 2            |\n",
      "|    gen/time/total_timesteps        | 188416       |\n",
      "|    gen/train/approx_kl             | 0.0069335713 |\n",
      "|    gen/train/clip_fraction         | 0.0532       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -1.04        |\n",
      "|    gen/train/explained_variance    | 0.0742       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.502        |\n",
      "|    gen/train/n_updates             | 220          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00305     |\n",
      "|    gen/train/value_loss            | 0.987        |\n",
      "-----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.69e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -6.43       |\n",
      "|    gen/time/fps                    | 5197        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 4           |\n",
      "|    gen/time/total_timesteps        | 196608      |\n",
      "|    gen/train/approx_kl             | 0.007120249 |\n",
      "|    gen/train/clip_fraction         | 0.0441      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -1.02       |\n",
      "|    gen/train/explained_variance    | 0.0793      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.455       |\n",
      "|    gen/train/n_updates             | 230         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00268    |\n",
      "|    gen/train/value_loss            | 0.855       |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.542    |\n",
      "|    disc/disc_acc_expert             | 0.973    |\n",
      "|    disc/disc_acc_gen                | 0.11     |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.781    |\n",
      "|    disc/disc_proportion_expert_pred | 0.931    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.966    |\n",
      "|    disc/disc_acc_gen                | 0.0991   |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.788    |\n",
      "|    disc/disc_proportion_expert_pred | 0.934    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.971    |\n",
      "|    disc/disc_acc_gen                | 0.0962   |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.772    |\n",
      "|    disc/disc_proportion_expert_pred | 0.938    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.54     |\n",
      "|    disc/disc_acc_expert             | 0.976    |\n",
      "|    disc/disc_acc_gen                | 0.105    |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.775    |\n",
      "|    disc/disc_proportion_expert_pred | 0.935    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.968    |\n",
      "|    disc/disc_acc_gen                | 0.0986   |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.79     |\n",
      "|    disc/disc_proportion_expert_pred | 0.935    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.971    |\n",
      "|    disc/disc_acc_gen                | 0.0986   |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.775    |\n",
      "|    disc/disc_proportion_expert_pred | 0.936    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.532    |\n",
      "|    disc/disc_acc_expert             | 0.965    |\n",
      "|    disc/disc_acc_gen                | 0.0991   |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.781    |\n",
      "|    disc/disc_proportion_expert_pred | 0.933    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.536    |\n",
      "|    disc/disc_acc_expert             | 0.965    |\n",
      "|    disc/disc_acc_gen                | 0.107    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.768    |\n",
      "|    disc/disc_proportion_expert_pred | 0.929    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.969    |\n",
      "|    disc/disc_acc_gen                | 0.0967   |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.778    |\n",
      "|    disc/disc_proportion_expert_pred | 0.936    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.532    |\n",
      "|    disc/disc_acc_expert             | 0.968    |\n",
      "|    disc/disc_acc_gen                | 0.0952   |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.78     |\n",
      "|    disc/disc_proportion_expert_pred | 0.937    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.536    |\n",
      "|    disc/disc_acc_expert             | 0.968    |\n",
      "|    disc/disc_acc_gen                | 0.104    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.772    |\n",
      "|    disc/disc_proportion_expert_pred | 0.932    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.532    |\n",
      "|    disc/disc_acc_expert             | 0.973    |\n",
      "|    disc/disc_acc_gen                | 0.0908   |\n",
      "|    disc/disc_entropy                | 0.493    |\n",
      "|    disc/disc_loss                   | 0.768    |\n",
      "|    disc/disc_proportion_expert_pred | 0.941    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.536    |\n",
      "|    disc/disc_acc_expert             | 0.967    |\n",
      "|    disc/disc_acc_gen                | 0.105    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.76     |\n",
      "|    disc/disc_proportion_expert_pred | 0.931    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.969    |\n",
      "|    disc/disc_acc_gen                | 0.0986   |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.776    |\n",
      "|    disc/disc_proportion_expert_pred | 0.935    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.974    |\n",
      "|    disc/disc_acc_gen                | 0.0933   |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.768    |\n",
      "|    disc/disc_proportion_expert_pred | 0.94     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.531    |\n",
      "|    disc/disc_acc_expert             | 0.971    |\n",
      "|    disc/disc_acc_gen                | 0.0913   |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.778    |\n",
      "|    disc/disc_proportion_expert_pred | 0.94     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.97     |\n",
      "|    disc/disc_acc_gen                | 0.0994   |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.776    |\n",
      "|    disc/disc_proportion_expert_pred | 0.935    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 7        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.7e+03  |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -5.42    |\n",
      "|    gen/time/fps                     | 7.49e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 1.88e+05 |\n",
      "|    gen/train/approx_kl              | 0.00762  |\n",
      "|    gen/train/clip_fraction          | 0.0628   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -1.02    |\n",
      "|    gen/train/explained_variance     | 0.0808   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.44     |\n",
      "|    gen/train/n_updates              | 230      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00411 |\n",
      "|    gen/train/value_loss             | 0.91     |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:46<01:26,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.65e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -5.97       |\n",
      "|    gen/time/fps                    | 11220       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 204800      |\n",
      "|    gen/train/approx_kl             | 0.008793866 |\n",
      "|    gen/train/clip_fraction         | 0.0911      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.994      |\n",
      "|    gen/train/explained_variance    | 0.0891      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.361       |\n",
      "|    gen/train/n_updates             | 240         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00659    |\n",
      "|    gen/train/value_loss            | 0.887       |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.72e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -8.52        |\n",
      "|    gen/time/fps                    | 6013         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 2            |\n",
      "|    gen/time/total_timesteps        | 212992       |\n",
      "|    gen/train/approx_kl             | 0.0066905953 |\n",
      "|    gen/train/clip_fraction         | 0.0589       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.974       |\n",
      "|    gen/train/explained_variance    | 0.0861       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.601        |\n",
      "|    gen/train/n_updates             | 250          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00437     |\n",
      "|    gen/train/value_loss            | 1.02         |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -9.31        |\n",
      "|    gen/time/fps                    | 5203         |\n",
      "|    gen/time/iterations             | 3            |\n",
      "|    gen/time/time_elapsed           | 4            |\n",
      "|    gen/time/total_timesteps        | 221184       |\n",
      "|    gen/train/approx_kl             | 0.0072274054 |\n",
      "|    gen/train/clip_fraction         | 0.0583       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.965       |\n",
      "|    gen/train/explained_variance    | 0.0921       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.469        |\n",
      "|    gen/train/n_updates             | 260          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00376     |\n",
      "|    gen/train/value_loss            | 0.964        |\n",
      "-----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.536    |\n",
      "|    disc/disc_acc_expert             | 0.946    |\n",
      "|    disc/disc_acc_gen                | 0.126    |\n",
      "|    disc/disc_entropy                | 0.495    |\n",
      "|    disc/disc_loss                   | 0.758    |\n",
      "|    disc/disc_proportion_expert_pred | 0.91     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.53     |\n",
      "|    disc/disc_acc_expert             | 0.95     |\n",
      "|    disc/disc_acc_gen                | 0.109    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.763    |\n",
      "|    disc/disc_proportion_expert_pred | 0.92     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.956    |\n",
      "|    disc/disc_acc_gen                | 0.11     |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.781    |\n",
      "|    disc/disc_proportion_expert_pred | 0.923    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.54     |\n",
      "|    disc/disc_acc_expert             | 0.955    |\n",
      "|    disc/disc_acc_gen                | 0.125    |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.772    |\n",
      "|    disc/disc_proportion_expert_pred | 0.915    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.539    |\n",
      "|    disc/disc_acc_expert             | 0.958    |\n",
      "|    disc/disc_acc_gen                | 0.119    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.757    |\n",
      "|    disc/disc_proportion_expert_pred | 0.92     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.949    |\n",
      "|    disc/disc_acc_gen                | 0.117    |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.76     |\n",
      "|    disc/disc_proportion_expert_pred | 0.916    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.537    |\n",
      "|    disc/disc_acc_expert             | 0.951    |\n",
      "|    disc/disc_acc_gen                | 0.123    |\n",
      "|    disc/disc_entropy                | 0.493    |\n",
      "|    disc/disc_loss                   | 0.766    |\n",
      "|    disc/disc_proportion_expert_pred | 0.914    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.95     |\n",
      "|    disc/disc_acc_gen                | 0.121    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.762    |\n",
      "|    disc/disc_proportion_expert_pred | 0.915    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.949    |\n",
      "|    disc/disc_acc_gen                | 0.119    |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.764    |\n",
      "|    disc/disc_proportion_expert_pred | 0.915    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.952    |\n",
      "|    disc/disc_acc_gen                | 0.114    |\n",
      "|    disc/disc_entropy                | 0.493    |\n",
      "|    disc/disc_loss                   | 0.762    |\n",
      "|    disc/disc_proportion_expert_pred | 0.919    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.537    |\n",
      "|    disc/disc_acc_expert             | 0.946    |\n",
      "|    disc/disc_acc_gen                | 0.128    |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.745    |\n",
      "|    disc/disc_proportion_expert_pred | 0.909    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.537    |\n",
      "|    disc/disc_acc_expert             | 0.952    |\n",
      "|    disc/disc_acc_gen                | 0.123    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.759    |\n",
      "|    disc/disc_proportion_expert_pred | 0.915    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.947    |\n",
      "|    disc/disc_acc_gen                | 0.121    |\n",
      "|    disc/disc_entropy                | 0.495    |\n",
      "|    disc/disc_loss                   | 0.755    |\n",
      "|    disc/disc_proportion_expert_pred | 0.913    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.529    |\n",
      "|    disc/disc_acc_expert             | 0.95     |\n",
      "|    disc/disc_acc_gen                | 0.108    |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.763    |\n",
      "|    disc/disc_proportion_expert_pred | 0.921    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.953    |\n",
      "|    disc/disc_acc_gen                | 0.115    |\n",
      "|    disc/disc_entropy                | 0.495    |\n",
      "|    disc/disc_loss                   | 0.764    |\n",
      "|    disc/disc_proportion_expert_pred | 0.919    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.543    |\n",
      "|    disc/disc_acc_expert             | 0.959    |\n",
      "|    disc/disc_acc_gen                | 0.126    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.757    |\n",
      "|    disc/disc_proportion_expert_pred | 0.916    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.951    |\n",
      "|    disc/disc_acc_gen                | 0.119    |\n",
      "|    disc/disc_entropy                | 0.493    |\n",
      "|    disc/disc_loss                   | 0.762    |\n",
      "|    disc/disc_proportion_expert_pred | 0.916    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 8        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.69e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -7.93    |\n",
      "|    gen/time/fps                     | 7.48e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 2.13e+05 |\n",
      "|    gen/train/approx_kl              | 0.00732  |\n",
      "|    gen/train/clip_fraction          | 0.0634   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.965   |\n",
      "|    gen/train/explained_variance     | 0.0914   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.505    |\n",
      "|    gen/train/n_updates              | 260      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00456 |\n",
      "|    gen/train/value_loss             | 0.955    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:52<01:18,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -9.48       |\n",
      "|    gen/time/fps                    | 11227       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 229376      |\n",
      "|    gen/train/approx_kl             | 0.008034572 |\n",
      "|    gen/train/clip_fraction         | 0.0732      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.957      |\n",
      "|    gen/train/explained_variance    | 0.0961      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.446       |\n",
      "|    gen/train/n_updates             | 270         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00554    |\n",
      "|    gen/train/value_loss            | 0.886       |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.64e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -11.8        |\n",
      "|    gen/time/fps                    | 5518         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 2            |\n",
      "|    gen/time/total_timesteps        | 237568       |\n",
      "|    gen/train/approx_kl             | 0.0072051394 |\n",
      "|    gen/train/clip_fraction         | 0.0562       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.936       |\n",
      "|    gen/train/explained_variance    | 0.0915       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.509        |\n",
      "|    gen/train/n_updates             | 280          |\n",
      "|    gen/train/policy_gradient_loss  | -0.004       |\n",
      "|    gen/train/value_loss            | 0.973        |\n",
      "-----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.68e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -12.4       |\n",
      "|    gen/time/fps                    | 4947        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 4           |\n",
      "|    gen/time/total_timesteps        | 245760      |\n",
      "|    gen/train/approx_kl             | 0.006636705 |\n",
      "|    gen/train/clip_fraction         | 0.0605      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.919      |\n",
      "|    gen/train/explained_variance    | 0.0885      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.486       |\n",
      "|    gen/train/n_updates             | 290         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00396    |\n",
      "|    gen/train/value_loss            | 1           |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.531    |\n",
      "|    disc/disc_acc_expert             | 0.955    |\n",
      "|    disc/disc_acc_gen                | 0.107    |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.743    |\n",
      "|    disc/disc_proportion_expert_pred | 0.924    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.529    |\n",
      "|    disc/disc_acc_expert             | 0.95     |\n",
      "|    disc/disc_acc_gen                | 0.109    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.76     |\n",
      "|    disc/disc_proportion_expert_pred | 0.92     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.53     |\n",
      "|    disc/disc_acc_expert             | 0.954    |\n",
      "|    disc/disc_acc_gen                | 0.107    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.752    |\n",
      "|    disc/disc_proportion_expert_pred | 0.923    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.958    |\n",
      "|    disc/disc_acc_gen                | 0.112    |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.76     |\n",
      "|    disc/disc_proportion_expert_pred | 0.923    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.524    |\n",
      "|    disc/disc_acc_expert             | 0.952    |\n",
      "|    disc/disc_acc_gen                | 0.0967   |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.77     |\n",
      "|    disc/disc_proportion_expert_pred | 0.928    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.53     |\n",
      "|    disc/disc_acc_expert             | 0.958    |\n",
      "|    disc/disc_acc_gen                | 0.102    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.749    |\n",
      "|    disc/disc_proportion_expert_pred | 0.928    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.526    |\n",
      "|    disc/disc_acc_expert             | 0.951    |\n",
      "|    disc/disc_acc_gen                | 0.101    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.759    |\n",
      "|    disc/disc_proportion_expert_pred | 0.925    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.526    |\n",
      "|    disc/disc_acc_expert             | 0.952    |\n",
      "|    disc/disc_acc_gen                | 0.101    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.763    |\n",
      "|    disc/disc_proportion_expert_pred | 0.926    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.958    |\n",
      "|    disc/disc_acc_gen                | 0.113    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.742    |\n",
      "|    disc/disc_proportion_expert_pred | 0.923    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.529    |\n",
      "|    disc/disc_acc_expert             | 0.954    |\n",
      "|    disc/disc_acc_gen                | 0.103    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.755    |\n",
      "|    disc/disc_proportion_expert_pred | 0.926    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 0.959    |\n",
      "|    disc/disc_acc_gen                | 0.107    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.76     |\n",
      "|    disc/disc_proportion_expert_pred | 0.926    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.531    |\n",
      "|    disc/disc_acc_expert             | 0.954    |\n",
      "|    disc/disc_acc_gen                | 0.107    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.756    |\n",
      "|    disc/disc_proportion_expert_pred | 0.923    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.532    |\n",
      "|    disc/disc_acc_expert             | 0.953    |\n",
      "|    disc/disc_acc_gen                | 0.111    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.758    |\n",
      "|    disc/disc_proportion_expert_pred | 0.921    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.534    |\n",
      "|    disc/disc_acc_expert             | 0.962    |\n",
      "|    disc/disc_acc_gen                | 0.105    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.739    |\n",
      "|    disc/disc_proportion_expert_pred | 0.929    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.535    |\n",
      "|    disc/disc_acc_expert             | 0.954    |\n",
      "|    disc/disc_acc_gen                | 0.116    |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.741    |\n",
      "|    disc/disc_proportion_expert_pred | 0.919    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.53     |\n",
      "|    disc/disc_acc_expert             | 0.95     |\n",
      "|    disc/disc_acc_gen                | 0.109    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.762    |\n",
      "|    disc/disc_proportion_expert_pred | 0.92     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.531    |\n",
      "|    disc/disc_acc_expert             | 0.955    |\n",
      "|    disc/disc_acc_gen                | 0.107    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.754    |\n",
      "|    disc/disc_proportion_expert_pred | 0.924    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 9        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.68e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -11.2    |\n",
      "|    gen/time/fps                     | 7.23e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 2.38e+05 |\n",
      "|    gen/train/approx_kl              | 0.00657  |\n",
      "|    gen/train/clip_fraction          | 0.0524   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.914   |\n",
      "|    gen/train/explained_variance     | 0.0931   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.459    |\n",
      "|    gen/train/n_updates              | 290      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00325 |\n",
      "|    gen/train/value_loss             | 0.916    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:59<01:12,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -11.7       |\n",
      "|    gen/time/fps                    | 9751        |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 253952      |\n",
      "|    gen/train/approx_kl             | 0.005858802 |\n",
      "|    gen/train/clip_fraction         | 0.0404      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.887      |\n",
      "|    gen/train/explained_variance    | 0.0993      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.383       |\n",
      "|    gen/train/n_updates             | 300         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00178    |\n",
      "|    gen/train/value_loss            | 0.771       |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.69e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -13.4        |\n",
      "|    gen/time/fps                    | 4977         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 3            |\n",
      "|    gen/time/total_timesteps        | 262144       |\n",
      "|    gen/train/approx_kl             | 0.0061101713 |\n",
      "|    gen/train/clip_fraction         | 0.0658       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.858       |\n",
      "|    gen/train/explained_variance    | 0.0944       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.358        |\n",
      "|    gen/train/n_updates             | 310          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00506     |\n",
      "|    gen/train/value_loss            | 0.859        |\n",
      "-----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.64e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -14.9       |\n",
      "|    gen/time/fps                    | 4455        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 5           |\n",
      "|    gen/time/total_timesteps        | 270336      |\n",
      "|    gen/train/approx_kl             | 0.005436823 |\n",
      "|    gen/train/clip_fraction         | 0.0628      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.823      |\n",
      "|    gen/train/explained_variance    | 0.0963      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.409       |\n",
      "|    gen/train/n_updates             | 320         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00483    |\n",
      "|    gen/train/value_loss            | 0.933       |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.557    |\n",
      "|    disc/disc_acc_expert             | 0.936    |\n",
      "|    disc/disc_acc_gen                | 0.178    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.7      |\n",
      "|    disc/disc_proportion_expert_pred | 0.879    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.552    |\n",
      "|    disc/disc_acc_expert             | 0.944    |\n",
      "|    disc/disc_acc_gen                | 0.161    |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.684    |\n",
      "|    disc/disc_proportion_expert_pred | 0.892    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.558    |\n",
      "|    disc/disc_acc_expert             | 0.934    |\n",
      "|    disc/disc_acc_gen                | 0.181    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.685    |\n",
      "|    disc/disc_proportion_expert_pred | 0.876    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.561    |\n",
      "|    disc/disc_acc_expert             | 0.945    |\n",
      "|    disc/disc_acc_gen                | 0.177    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.69     |\n",
      "|    disc/disc_proportion_expert_pred | 0.884    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.556    |\n",
      "|    disc/disc_acc_expert             | 0.938    |\n",
      "|    disc/disc_acc_gen                | 0.173    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.693    |\n",
      "|    disc/disc_proportion_expert_pred | 0.883    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.551    |\n",
      "|    disc/disc_acc_expert             | 0.936    |\n",
      "|    disc/disc_acc_gen                | 0.166    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.698    |\n",
      "|    disc/disc_proportion_expert_pred | 0.885    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.547    |\n",
      "|    disc/disc_acc_expert             | 0.931    |\n",
      "|    disc/disc_acc_gen                | 0.163    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.706    |\n",
      "|    disc/disc_proportion_expert_pred | 0.884    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.551    |\n",
      "|    disc/disc_acc_expert             | 0.932    |\n",
      "|    disc/disc_acc_gen                | 0.17     |\n",
      "|    disc/disc_entropy                | 0.493    |\n",
      "|    disc/disc_loss                   | 0.687    |\n",
      "|    disc/disc_proportion_expert_pred | 0.881    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.557    |\n",
      "|    disc/disc_acc_expert             | 0.941    |\n",
      "|    disc/disc_acc_gen                | 0.173    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.697    |\n",
      "|    disc/disc_proportion_expert_pred | 0.884    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.554    |\n",
      "|    disc/disc_acc_expert             | 0.942    |\n",
      "|    disc/disc_acc_gen                | 0.166    |\n",
      "|    disc/disc_entropy                | 0.493    |\n",
      "|    disc/disc_loss                   | 0.681    |\n",
      "|    disc/disc_proportion_expert_pred | 0.888    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.556    |\n",
      "|    disc/disc_acc_expert             | 0.942    |\n",
      "|    disc/disc_acc_gen                | 0.171    |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.692    |\n",
      "|    disc/disc_proportion_expert_pred | 0.885    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.55     |\n",
      "|    disc/disc_acc_expert             | 0.936    |\n",
      "|    disc/disc_acc_gen                | 0.164    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.703    |\n",
      "|    disc/disc_proportion_expert_pred | 0.886    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.55     |\n",
      "|    disc/disc_acc_expert             | 0.937    |\n",
      "|    disc/disc_acc_gen                | 0.164    |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.693    |\n",
      "|    disc/disc_proportion_expert_pred | 0.887    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.56     |\n",
      "|    disc/disc_acc_expert             | 0.936    |\n",
      "|    disc/disc_acc_gen                | 0.185    |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.688    |\n",
      "|    disc/disc_proportion_expert_pred | 0.875    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.551    |\n",
      "|    disc/disc_acc_expert             | 0.935    |\n",
      "|    disc/disc_acc_gen                | 0.167    |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.7      |\n",
      "|    disc/disc_proportion_expert_pred | 0.884    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.564    |\n",
      "|    disc/disc_acc_expert             | 0.936    |\n",
      "|    disc/disc_acc_gen                | 0.193    |\n",
      "|    disc/disc_entropy                | 0.494    |\n",
      "|    disc/disc_loss                   | 0.679    |\n",
      "|    disc/disc_proportion_expert_pred | 0.871    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.555    |\n",
      "|    disc/disc_acc_expert             | 0.938    |\n",
      "|    disc/disc_acc_gen                | 0.172    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.692    |\n",
      "|    disc/disc_proportion_expert_pred | 0.883    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 10       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.68e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -13.3    |\n",
      "|    gen/time/fps                     | 6.39e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.67     |\n",
      "|    gen/time/total_timesteps         | 2.62e+05 |\n",
      "|    gen/train/approx_kl              | 0.00576  |\n",
      "|    gen/train/clip_fraction          | 0.0661   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.826   |\n",
      "|    gen/train/explained_variance     | 0.0945   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.396    |\n",
      "|    gen/train/n_updates              | 320      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00496 |\n",
      "|    gen/train/value_loss             | 0.855    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:07<01:08,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.69e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -14.5       |\n",
      "|    gen/time/fps                    | 11051       |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 278528      |\n",
      "|    gen/train/approx_kl             | 0.005741942 |\n",
      "|    gen/train/clip_fraction         | 0.0697      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.798      |\n",
      "|    gen/train/explained_variance    | 0.0928      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.421       |\n",
      "|    gen/train/n_updates             | 330         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00498    |\n",
      "|    gen/train/value_loss            | 0.771       |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.72e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -16.8        |\n",
      "|    gen/time/fps                    | 5627         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 2            |\n",
      "|    gen/time/total_timesteps        | 286720       |\n",
      "|    gen/train/approx_kl             | 0.0038243998 |\n",
      "|    gen/train/clip_fraction         | 0.0353       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.809       |\n",
      "|    gen/train/explained_variance    | 0.0948       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.493        |\n",
      "|    gen/train/n_updates             | 340          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00162     |\n",
      "|    gen/train/value_loss            | 0.903        |\n",
      "-----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.7e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -16.9       |\n",
      "|    gen/time/fps                    | 4754        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 5           |\n",
      "|    gen/time/total_timesteps        | 294912      |\n",
      "|    gen/train/approx_kl             | 0.005697542 |\n",
      "|    gen/train/clip_fraction         | 0.0646      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.804      |\n",
      "|    gen/train/explained_variance    | 0.0953      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.363       |\n",
      "|    gen/train/n_updates             | 350         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00399    |\n",
      "|    gen/train/value_loss            | 0.759       |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.613    |\n",
      "|    disc/disc_acc_expert             | 0.926    |\n",
      "|    disc/disc_acc_gen                | 0.299    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.638    |\n",
      "|    disc/disc_proportion_expert_pred | 0.813    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.588    |\n",
      "|    disc/disc_acc_expert             | 0.913    |\n",
      "|    disc/disc_acc_gen                | 0.262    |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.686    |\n",
      "|    disc/disc_proportion_expert_pred | 0.825    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.594    |\n",
      "|    disc/disc_acc_expert             | 0.923    |\n",
      "|    disc/disc_acc_gen                | 0.265    |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.665    |\n",
      "|    disc/disc_proportion_expert_pred | 0.829    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.602    |\n",
      "|    disc/disc_acc_expert             | 0.927    |\n",
      "|    disc/disc_acc_gen                | 0.277    |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.651    |\n",
      "|    disc/disc_proportion_expert_pred | 0.825    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.594    |\n",
      "|    disc/disc_acc_expert             | 0.924    |\n",
      "|    disc/disc_acc_gen                | 0.265    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.658    |\n",
      "|    disc/disc_proportion_expert_pred | 0.83     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.603    |\n",
      "|    disc/disc_acc_expert             | 0.922    |\n",
      "|    disc/disc_acc_gen                | 0.284    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.66     |\n",
      "|    disc/disc_proportion_expert_pred | 0.819    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.592    |\n",
      "|    disc/disc_acc_expert             | 0.917    |\n",
      "|    disc/disc_acc_gen                | 0.267    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.669    |\n",
      "|    disc/disc_proportion_expert_pred | 0.825    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.599    |\n",
      "|    disc/disc_acc_expert             | 0.917    |\n",
      "|    disc/disc_acc_gen                | 0.282    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.641    |\n",
      "|    disc/disc_proportion_expert_pred | 0.818    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.594    |\n",
      "|    disc/disc_acc_expert             | 0.931    |\n",
      "|    disc/disc_acc_gen                | 0.256    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.659    |\n",
      "|    disc/disc_proportion_expert_pred | 0.838    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.6      |\n",
      "|    disc/disc_acc_expert             | 0.932    |\n",
      "|    disc/disc_acc_gen                | 0.268    |\n",
      "|    disc/disc_entropy                | 0.491    |\n",
      "|    disc/disc_loss                   | 0.658    |\n",
      "|    disc/disc_proportion_expert_pred | 0.832    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.595    |\n",
      "|    disc/disc_acc_expert             | 0.927    |\n",
      "|    disc/disc_acc_gen                | 0.262    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.658    |\n",
      "|    disc/disc_proportion_expert_pred | 0.833    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.592    |\n",
      "|    disc/disc_acc_expert             | 0.916    |\n",
      "|    disc/disc_acc_gen                | 0.268    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.671    |\n",
      "|    disc/disc_proportion_expert_pred | 0.824    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.593    |\n",
      "|    disc/disc_acc_expert             | 0.905    |\n",
      "|    disc/disc_acc_gen                | 0.281    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.652    |\n",
      "|    disc/disc_proportion_expert_pred | 0.812    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.595    |\n",
      "|    disc/disc_acc_expert             | 0.913    |\n",
      "|    disc/disc_acc_gen                | 0.278    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.654    |\n",
      "|    disc/disc_proportion_expert_pred | 0.817    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.601    |\n",
      "|    disc/disc_acc_expert             | 0.929    |\n",
      "|    disc/disc_acc_gen                | 0.272    |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.657    |\n",
      "|    disc/disc_proportion_expert_pred | 0.828    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.598    |\n",
      "|    disc/disc_acc_expert             | 0.917    |\n",
      "|    disc/disc_acc_gen                | 0.28     |\n",
      "|    disc/disc_entropy                | 0.495    |\n",
      "|    disc/disc_loss                   | 0.65     |\n",
      "|    disc/disc_proportion_expert_pred | 0.818    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.597    |\n",
      "|    disc/disc_acc_expert             | 0.921    |\n",
      "|    disc/disc_acc_gen                | 0.273    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.658    |\n",
      "|    disc/disc_proportion_expert_pred | 0.824    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 11       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.71e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -16      |\n",
      "|    gen/time/fps                     | 7.14e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.33     |\n",
      "|    gen/time/total_timesteps         | 2.87e+05 |\n",
      "|    gen/train/approx_kl              | 0.00511  |\n",
      "|    gen/train/clip_fraction          | 0.0528   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.796   |\n",
      "|    gen/train/explained_variance     | 0.0985   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.422    |\n",
      "|    gen/train/n_updates              | 350      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00325 |\n",
      "|    gen/train/value_loss             | 0.837    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:14<01:03,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.66e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -16.5       |\n",
      "|    gen/time/fps                    | 9858        |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 303104      |\n",
      "|    gen/train/approx_kl             | 0.005797805 |\n",
      "|    gen/train/clip_fraction         | 0.0586      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.775      |\n",
      "|    gen/train/explained_variance    | 0.105       |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.41        |\n",
      "|    gen/train/n_updates             | 360         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00414    |\n",
      "|    gen/train/value_loss            | 0.848       |\n",
      "----------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| raw/                               |            |\n",
      "|    gen/rollout/ep_len_mean         | 100        |\n",
      "|    gen/rollout/ep_rew_mean         | 4.7e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -19.1      |\n",
      "|    gen/time/fps                    | 5323       |\n",
      "|    gen/time/iterations             | 2          |\n",
      "|    gen/time/time_elapsed           | 3          |\n",
      "|    gen/time/total_timesteps        | 311296     |\n",
      "|    gen/train/approx_kl             | 0.00445261 |\n",
      "|    gen/train/clip_fraction         | 0.0487     |\n",
      "|    gen/train/clip_range            | 0.2        |\n",
      "|    gen/train/entropy_loss          | -0.755     |\n",
      "|    gen/train/explained_variance    | 0.0878     |\n",
      "|    gen/train/learning_rate         | 0.0003     |\n",
      "|    gen/train/loss                  | 0.319      |\n",
      "|    gen/train/n_updates             | 370        |\n",
      "|    gen/train/policy_gradient_loss  | -0.00247   |\n",
      "|    gen/train/value_loss            | 0.762      |\n",
      "---------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.69e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -19.3       |\n",
      "|    gen/time/fps                    | 4579        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 5           |\n",
      "|    gen/time/total_timesteps        | 319488      |\n",
      "|    gen/train/approx_kl             | 0.005436592 |\n",
      "|    gen/train/clip_fraction         | 0.0492      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.746      |\n",
      "|    gen/train/explained_variance    | 0.0982      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.362       |\n",
      "|    gen/train/n_updates             | 380         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00318    |\n",
      "|    gen/train/value_loss            | 0.89        |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.651    |\n",
      "|    disc/disc_acc_expert             | 0.885    |\n",
      "|    disc/disc_acc_gen                | 0.418    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.668    |\n",
      "|    disc/disc_proportion_expert_pred | 0.733    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.647    |\n",
      "|    disc/disc_acc_expert             | 0.887    |\n",
      "|    disc/disc_acc_gen                | 0.407    |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.662    |\n",
      "|    disc/disc_proportion_expert_pred | 0.74     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.655    |\n",
      "|    disc/disc_acc_expert             | 0.89     |\n",
      "|    disc/disc_acc_gen                | 0.42     |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.644    |\n",
      "|    disc/disc_proportion_expert_pred | 0.735    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.656    |\n",
      "|    disc/disc_acc_expert             | 0.895    |\n",
      "|    disc/disc_acc_gen                | 0.416    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.661    |\n",
      "|    disc/disc_proportion_expert_pred | 0.74     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.642    |\n",
      "|    disc/disc_acc_expert             | 0.882    |\n",
      "|    disc/disc_acc_gen                | 0.401    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.66     |\n",
      "|    disc/disc_proportion_expert_pred | 0.74     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.648    |\n",
      "|    disc/disc_acc_expert             | 0.89     |\n",
      "|    disc/disc_acc_gen                | 0.406    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.664    |\n",
      "|    disc/disc_proportion_expert_pred | 0.742    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.645    |\n",
      "|    disc/disc_acc_expert             | 0.886    |\n",
      "|    disc/disc_acc_gen                | 0.404    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.68     |\n",
      "|    disc/disc_proportion_expert_pred | 0.741    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.665    |\n",
      "|    disc/disc_acc_expert             | 0.901    |\n",
      "|    disc/disc_acc_gen                | 0.429    |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.654    |\n",
      "|    disc/disc_proportion_expert_pred | 0.736    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.654    |\n",
      "|    disc/disc_acc_expert             | 0.887    |\n",
      "|    disc/disc_acc_gen                | 0.42     |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.655    |\n",
      "|    disc/disc_proportion_expert_pred | 0.733    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.65     |\n",
      "|    disc/disc_acc_expert             | 0.882    |\n",
      "|    disc/disc_acc_gen                | 0.417    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.673    |\n",
      "|    disc/disc_proportion_expert_pred | 0.732    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.654    |\n",
      "|    disc/disc_acc_expert             | 0.891    |\n",
      "|    disc/disc_acc_gen                | 0.417    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.666    |\n",
      "|    disc/disc_proportion_expert_pred | 0.737    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.656    |\n",
      "|    disc/disc_acc_expert             | 0.89     |\n",
      "|    disc/disc_acc_gen                | 0.422    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.654    |\n",
      "|    disc/disc_proportion_expert_pred | 0.734    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.65     |\n",
      "|    disc/disc_acc_expert             | 0.892    |\n",
      "|    disc/disc_acc_gen                | 0.408    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.646    |\n",
      "|    disc/disc_proportion_expert_pred | 0.742    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.655    |\n",
      "|    disc/disc_acc_expert             | 0.893    |\n",
      "|    disc/disc_acc_gen                | 0.417    |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.656    |\n",
      "|    disc/disc_proportion_expert_pred | 0.738    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.652    |\n",
      "|    disc/disc_acc_expert             | 0.896    |\n",
      "|    disc/disc_acc_gen                | 0.408    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.654    |\n",
      "|    disc/disc_proportion_expert_pred | 0.744    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.655    |\n",
      "|    disc/disc_acc_expert             | 0.887    |\n",
      "|    disc/disc_acc_gen                | 0.424    |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.663    |\n",
      "|    disc/disc_proportion_expert_pred | 0.731    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.652    |\n",
      "|    disc/disc_acc_expert             | 0.89     |\n",
      "|    disc/disc_acc_gen                | 0.415    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.66     |\n",
      "|    disc/disc_proportion_expert_pred | 0.737    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 12       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.68e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -18.3    |\n",
      "|    gen/time/fps                     | 6.59e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.67     |\n",
      "|    gen/time/total_timesteps         | 3.11e+05 |\n",
      "|    gen/train/approx_kl              | 0.00484  |\n",
      "|    gen/train/clip_fraction          | 0.0454   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.74    |\n",
      "|    gen/train/explained_variance     | 0.096    |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.329    |\n",
      "|    gen/train/n_updates              | 380      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00249 |\n",
      "|    gen/train/value_loss             | 0.817    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:22<00:58,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.67e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -19.2        |\n",
      "|    gen/time/fps                    | 9680         |\n",
      "|    gen/time/iterations             | 1            |\n",
      "|    gen/time/time_elapsed           | 0            |\n",
      "|    gen/time/total_timesteps        | 327680       |\n",
      "|    gen/train/approx_kl             | 0.0046292916 |\n",
      "|    gen/train/clip_fraction         | 0.0384       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.72        |\n",
      "|    gen/train/explained_variance    | 0.102        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.306        |\n",
      "|    gen/train/n_updates             | 390          |\n",
      "|    gen/train/policy_gradient_loss  | -0.0018      |\n",
      "|    gen/train/value_loss            | 0.799        |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.65e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -21.1        |\n",
      "|    gen/time/fps                    | 4585         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 3            |\n",
      "|    gen/time/total_timesteps        | 335872       |\n",
      "|    gen/train/approx_kl             | 0.0047303867 |\n",
      "|    gen/train/clip_fraction         | 0.0605       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.741       |\n",
      "|    gen/train/explained_variance    | 0.0953       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.328        |\n",
      "|    gen/train/n_updates             | 400          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00425     |\n",
      "|    gen/train/value_loss            | 0.844        |\n",
      "-----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.77e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -21.5       |\n",
      "|    gen/time/fps                    | 3671        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 6           |\n",
      "|    gen/time/total_timesteps        | 344064      |\n",
      "|    gen/train/approx_kl             | 0.004305436 |\n",
      "|    gen/train/clip_fraction         | 0.0437      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.747      |\n",
      "|    gen/train/explained_variance    | 0.105       |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.41        |\n",
      "|    gen/train/n_updates             | 410         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00258    |\n",
      "|    gen/train/value_loss            | 0.786       |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.63     |\n",
      "|    disc/disc_acc_expert             | 0.891    |\n",
      "|    disc/disc_acc_gen                | 0.369    |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.665    |\n",
      "|    disc/disc_proportion_expert_pred | 0.761    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.635    |\n",
      "|    disc/disc_acc_expert             | 0.894    |\n",
      "|    disc/disc_acc_gen                | 0.377    |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.648    |\n",
      "|    disc/disc_proportion_expert_pred | 0.759    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.628    |\n",
      "|    disc/disc_acc_expert             | 0.894    |\n",
      "|    disc/disc_acc_gen                | 0.361    |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.675    |\n",
      "|    disc/disc_proportion_expert_pred | 0.766    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.63     |\n",
      "|    disc/disc_acc_expert             | 0.89     |\n",
      "|    disc/disc_acc_gen                | 0.37     |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.658    |\n",
      "|    disc/disc_proportion_expert_pred | 0.76     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.628    |\n",
      "|    disc/disc_acc_expert             | 0.896    |\n",
      "|    disc/disc_acc_gen                | 0.36     |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.65     |\n",
      "|    disc/disc_proportion_expert_pred | 0.768    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.627    |\n",
      "|    disc/disc_acc_expert             | 0.881    |\n",
      "|    disc/disc_acc_gen                | 0.373    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.656    |\n",
      "|    disc/disc_proportion_expert_pred | 0.754    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.641    |\n",
      "|    disc/disc_acc_expert             | 0.884    |\n",
      "|    disc/disc_acc_gen                | 0.397    |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.652    |\n",
      "|    disc/disc_proportion_expert_pred | 0.743    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.627    |\n",
      "|    disc/disc_acc_expert             | 0.876    |\n",
      "|    disc/disc_acc_gen                | 0.377    |\n",
      "|    disc/disc_entropy                | 0.492    |\n",
      "|    disc/disc_loss                   | 0.661    |\n",
      "|    disc/disc_proportion_expert_pred | 0.75     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.629    |\n",
      "|    disc/disc_acc_expert             | 0.894    |\n",
      "|    disc/disc_acc_gen                | 0.364    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.66     |\n",
      "|    disc/disc_proportion_expert_pred | 0.765    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.621    |\n",
      "|    disc/disc_acc_expert             | 0.885    |\n",
      "|    disc/disc_acc_gen                | 0.358    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.66     |\n",
      "|    disc/disc_proportion_expert_pred | 0.763    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.637    |\n",
      "|    disc/disc_acc_expert             | 0.89     |\n",
      "|    disc/disc_acc_gen                | 0.384    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.65     |\n",
      "|    disc/disc_proportion_expert_pred | 0.753    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.634    |\n",
      "|    disc/disc_acc_expert             | 0.898    |\n",
      "|    disc/disc_acc_gen                | 0.371    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.653    |\n",
      "|    disc/disc_proportion_expert_pred | 0.764    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.634    |\n",
      "|    disc/disc_acc_expert             | 0.896    |\n",
      "|    disc/disc_acc_gen                | 0.373    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.664    |\n",
      "|    disc/disc_proportion_expert_pred | 0.761    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.643    |\n",
      "|    disc/disc_acc_expert             | 0.892    |\n",
      "|    disc/disc_acc_gen                | 0.394    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.65     |\n",
      "|    disc/disc_proportion_expert_pred | 0.749    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.626    |\n",
      "|    disc/disc_acc_expert             | 0.888    |\n",
      "|    disc/disc_acc_gen                | 0.365    |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.646    |\n",
      "|    disc/disc_proportion_expert_pred | 0.762    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.637    |\n",
      "|    disc/disc_acc_expert             | 0.896    |\n",
      "|    disc/disc_acc_gen                | 0.378    |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.654    |\n",
      "|    disc/disc_proportion_expert_pred | 0.759    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.632    |\n",
      "|    disc/disc_acc_expert             | 0.89     |\n",
      "|    disc/disc_acc_gen                | 0.373    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.657    |\n",
      "|    disc/disc_proportion_expert_pred | 0.759    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 13       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.7e+03  |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -20.6    |\n",
      "|    gen/time/fps                     | 5.98e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 3        |\n",
      "|    gen/time/total_timesteps         | 3.36e+05 |\n",
      "|    gen/train/approx_kl              | 0.00444  |\n",
      "|    gen/train/clip_fraction          | 0.0505   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.735   |\n",
      "|    gen/train/explained_variance     | 0.0999   |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.403    |\n",
      "|    gen/train/n_updates              | 410      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00321 |\n",
      "|    gen/train/value_loss             | 0.798    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:30<00:53,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.74e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -21.7        |\n",
      "|    gen/time/fps                    | 8657         |\n",
      "|    gen/time/iterations             | 1            |\n",
      "|    gen/time/time_elapsed           | 0            |\n",
      "|    gen/time/total_timesteps        | 352256       |\n",
      "|    gen/train/approx_kl             | 0.0042950725 |\n",
      "|    gen/train/clip_fraction         | 0.0472       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.716       |\n",
      "|    gen/train/explained_variance    | 0.0991       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.472        |\n",
      "|    gen/train/n_updates             | 420          |\n",
      "|    gen/train/policy_gradient_loss  | -0.0028      |\n",
      "|    gen/train/value_loss            | 0.763        |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.68e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -23.7        |\n",
      "|    gen/time/fps                    | 5000         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 3            |\n",
      "|    gen/time/total_timesteps        | 360448       |\n",
      "|    gen/train/approx_kl             | 0.0051022614 |\n",
      "|    gen/train/clip_fraction         | 0.0468       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.691       |\n",
      "|    gen/train/explained_variance    | 0.097        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.356        |\n",
      "|    gen/train/n_updates             | 430          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00299     |\n",
      "|    gen/train/value_loss            | 0.844        |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.68e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -24.2        |\n",
      "|    gen/time/fps                    | 4233         |\n",
      "|    gen/time/iterations             | 3            |\n",
      "|    gen/time/time_elapsed           | 5            |\n",
      "|    gen/time/total_timesteps        | 368640       |\n",
      "|    gen/train/approx_kl             | 0.0033452897 |\n",
      "|    gen/train/clip_fraction         | 0.0375       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.686       |\n",
      "|    gen/train/explained_variance    | 0.104        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.385        |\n",
      "|    gen/train/n_updates             | 440          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00191     |\n",
      "|    gen/train/value_loss            | 0.734        |\n",
      "-----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.643    |\n",
      "|    disc/disc_acc_expert             | 0.891    |\n",
      "|    disc/disc_acc_gen                | 0.396    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.626    |\n",
      "|    disc/disc_proportion_expert_pred | 0.748    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.631    |\n",
      "|    disc/disc_acc_expert             | 0.883    |\n",
      "|    disc/disc_acc_gen                | 0.379    |\n",
      "|    disc/disc_entropy                | 0.488    |\n",
      "|    disc/disc_loss                   | 0.627    |\n",
      "|    disc/disc_proportion_expert_pred | 0.752    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.64     |\n",
      "|    disc/disc_acc_expert             | 0.893    |\n",
      "|    disc/disc_acc_gen                | 0.388    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.633    |\n",
      "|    disc/disc_proportion_expert_pred | 0.752    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.639    |\n",
      "|    disc/disc_acc_expert             | 0.905    |\n",
      "|    disc/disc_acc_gen                | 0.372    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.623    |\n",
      "|    disc/disc_proportion_expert_pred | 0.767    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.628    |\n",
      "|    disc/disc_acc_expert             | 0.876    |\n",
      "|    disc/disc_acc_gen                | 0.379    |\n",
      "|    disc/disc_entropy                | 0.489    |\n",
      "|    disc/disc_loss                   | 0.632    |\n",
      "|    disc/disc_proportion_expert_pred | 0.748    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.642    |\n",
      "|    disc/disc_acc_expert             | 0.891    |\n",
      "|    disc/disc_acc_gen                | 0.394    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.631    |\n",
      "|    disc/disc_proportion_expert_pred | 0.749    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.64     |\n",
      "|    disc/disc_acc_expert             | 0.891    |\n",
      "|    disc/disc_acc_gen                | 0.39     |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.625    |\n",
      "|    disc/disc_proportion_expert_pred | 0.75     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.64     |\n",
      "|    disc/disc_acc_expert             | 0.878    |\n",
      "|    disc/disc_acc_gen                | 0.402    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.628    |\n",
      "|    disc/disc_proportion_expert_pred | 0.738    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.642    |\n",
      "|    disc/disc_acc_expert             | 0.898    |\n",
      "|    disc/disc_acc_gen                | 0.385    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.617    |\n",
      "|    disc/disc_proportion_expert_pred | 0.757    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.645    |\n",
      "|    disc/disc_acc_expert             | 0.899    |\n",
      "|    disc/disc_acc_gen                | 0.392    |\n",
      "|    disc/disc_entropy                | 0.486    |\n",
      "|    disc/disc_loss                   | 0.623    |\n",
      "|    disc/disc_proportion_expert_pred | 0.754    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.632    |\n",
      "|    disc/disc_acc_expert             | 0.885    |\n",
      "|    disc/disc_acc_gen                | 0.378    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.633    |\n",
      "|    disc/disc_proportion_expert_pred | 0.753    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.631    |\n",
      "|    disc/disc_acc_expert             | 0.891    |\n",
      "|    disc/disc_acc_gen                | 0.372    |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.624    |\n",
      "|    disc/disc_proportion_expert_pred | 0.76     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.645    |\n",
      "|    disc/disc_acc_expert             | 0.896    |\n",
      "|    disc/disc_acc_gen                | 0.394    |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.618    |\n",
      "|    disc/disc_proportion_expert_pred | 0.751    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.643    |\n",
      "|    disc/disc_acc_expert             | 0.896    |\n",
      "|    disc/disc_acc_gen                | 0.389    |\n",
      "|    disc/disc_entropy                | 0.487    |\n",
      "|    disc/disc_loss                   | 0.618    |\n",
      "|    disc/disc_proportion_expert_pred | 0.753    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.63     |\n",
      "|    disc/disc_acc_expert             | 0.886    |\n",
      "|    disc/disc_acc_gen                | 0.374    |\n",
      "|    disc/disc_entropy                | 0.49     |\n",
      "|    disc/disc_loss                   | 0.619    |\n",
      "|    disc/disc_proportion_expert_pred | 0.756    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.645    |\n",
      "|    disc/disc_acc_expert             | 0.881    |\n",
      "|    disc/disc_acc_gen                | 0.409    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.628    |\n",
      "|    disc/disc_proportion_expert_pred | 0.736    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.639    |\n",
      "|    disc/disc_acc_expert             | 0.89     |\n",
      "|    disc/disc_acc_gen                | 0.387    |\n",
      "|    disc/disc_entropy                | 0.485    |\n",
      "|    disc/disc_loss                   | 0.625    |\n",
      "|    disc/disc_proportion_expert_pred | 0.752    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 14       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.7e+03  |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -23.2    |\n",
      "|    gen/time/fps                     | 5.96e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.67     |\n",
      "|    gen/time/total_timesteps         | 3.6e+05  |\n",
      "|    gen/train/approx_kl              | 0.00417  |\n",
      "|    gen/train/clip_fraction          | 0.043    |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.679   |\n",
      "|    gen/train/explained_variance     | 0.104    |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.336    |\n",
      "|    gen/train/n_updates              | 440      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00248 |\n",
      "|    gen/train/value_loss             | 0.75     |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:38<00:45,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "| raw/                               |           |\n",
      "|    gen/rollout/ep_len_mean         | 100       |\n",
      "|    gen/rollout/ep_rew_mean         | 4.65e+03  |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -24.4     |\n",
      "|    gen/time/fps                    | 10716     |\n",
      "|    gen/time/iterations             | 1         |\n",
      "|    gen/time/time_elapsed           | 0         |\n",
      "|    gen/time/total_timesteps        | 376832    |\n",
      "|    gen/train/approx_kl             | 0.0040518 |\n",
      "|    gen/train/clip_fraction         | 0.0448    |\n",
      "|    gen/train/clip_range            | 0.2       |\n",
      "|    gen/train/entropy_loss          | -0.661    |\n",
      "|    gen/train/explained_variance    | 0.11      |\n",
      "|    gen/train/learning_rate         | 0.0003    |\n",
      "|    gen/train/loss                  | 0.268     |\n",
      "|    gen/train/n_updates             | 450       |\n",
      "|    gen/train/policy_gradient_loss  | -0.00252  |\n",
      "|    gen/train/value_loss            | 0.671     |\n",
      "--------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.63e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -26          |\n",
      "|    gen/time/fps                    | 5290         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 3            |\n",
      "|    gen/time/total_timesteps        | 385024       |\n",
      "|    gen/train/approx_kl             | 0.0041278265 |\n",
      "|    gen/train/clip_fraction         | 0.0536       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.66        |\n",
      "|    gen/train/explained_variance    | 0.101        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.387        |\n",
      "|    gen/train/n_updates             | 460          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00329     |\n",
      "|    gen/train/value_loss            | 0.859        |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.73e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -27.2        |\n",
      "|    gen/time/fps                    | 4135         |\n",
      "|    gen/time/iterations             | 3            |\n",
      "|    gen/time/time_elapsed           | 5            |\n",
      "|    gen/time/total_timesteps        | 393216       |\n",
      "|    gen/train/approx_kl             | 0.0035527528 |\n",
      "|    gen/train/clip_fraction         | 0.0414       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.618       |\n",
      "|    gen/train/explained_variance    | 0.102        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.21         |\n",
      "|    gen/train/n_updates             | 470          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00271     |\n",
      "|    gen/train/value_loss            | 0.726        |\n",
      "-----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.657    |\n",
      "|    disc/disc_acc_expert             | 0.872    |\n",
      "|    disc/disc_acc_gen                | 0.442    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.615    |\n",
      "|    disc/disc_proportion_expert_pred | 0.715    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.659    |\n",
      "|    disc/disc_acc_expert             | 0.874    |\n",
      "|    disc/disc_acc_gen                | 0.444    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.629    |\n",
      "|    disc/disc_proportion_expert_pred | 0.715    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.664    |\n",
      "|    disc/disc_acc_expert             | 0.878    |\n",
      "|    disc/disc_acc_gen                | 0.449    |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.603    |\n",
      "|    disc/disc_proportion_expert_pred | 0.715    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.652    |\n",
      "|    disc/disc_acc_expert             | 0.866    |\n",
      "|    disc/disc_acc_gen                | 0.438    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.614    |\n",
      "|    disc/disc_proportion_expert_pred | 0.714    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.654    |\n",
      "|    disc/disc_acc_expert             | 0.867    |\n",
      "|    disc/disc_acc_gen                | 0.44     |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.623    |\n",
      "|    disc/disc_proportion_expert_pred | 0.713    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.652    |\n",
      "|    disc/disc_acc_expert             | 0.867    |\n",
      "|    disc/disc_acc_gen                | 0.437    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.624    |\n",
      "|    disc/disc_proportion_expert_pred | 0.715    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.669    |\n",
      "|    disc/disc_acc_expert             | 0.881    |\n",
      "|    disc/disc_acc_gen                | 0.458    |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.608    |\n",
      "|    disc/disc_proportion_expert_pred | 0.712    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.658    |\n",
      "|    disc/disc_acc_expert             | 0.882    |\n",
      "|    disc/disc_acc_gen                | 0.435    |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.632    |\n",
      "|    disc/disc_proportion_expert_pred | 0.724    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.66     |\n",
      "|    disc/disc_acc_expert             | 0.871    |\n",
      "|    disc/disc_acc_gen                | 0.45     |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.618    |\n",
      "|    disc/disc_proportion_expert_pred | 0.711    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.666    |\n",
      "|    disc/disc_acc_expert             | 0.871    |\n",
      "|    disc/disc_acc_gen                | 0.46     |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.605    |\n",
      "|    disc/disc_proportion_expert_pred | 0.706    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.654    |\n",
      "|    disc/disc_acc_expert             | 0.865    |\n",
      "|    disc/disc_acc_gen                | 0.443    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.623    |\n",
      "|    disc/disc_proportion_expert_pred | 0.711    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.66     |\n",
      "|    disc/disc_acc_expert             | 0.862    |\n",
      "|    disc/disc_acc_gen                | 0.459    |\n",
      "|    disc/disc_entropy                | 0.484    |\n",
      "|    disc/disc_loss                   | 0.608    |\n",
      "|    disc/disc_proportion_expert_pred | 0.701    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.656    |\n",
      "|    disc/disc_acc_expert             | 0.878    |\n",
      "|    disc/disc_acc_gen                | 0.433    |\n",
      "|    disc/disc_entropy                | 0.481    |\n",
      "|    disc/disc_loss                   | 0.626    |\n",
      "|    disc/disc_proportion_expert_pred | 0.722    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.666    |\n",
      "|    disc/disc_acc_expert             | 0.881    |\n",
      "|    disc/disc_acc_gen                | 0.451    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.602    |\n",
      "|    disc/disc_proportion_expert_pred | 0.715    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.662    |\n",
      "|    disc/disc_acc_expert             | 0.882    |\n",
      "|    disc/disc_acc_gen                | 0.442    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.613    |\n",
      "|    disc/disc_proportion_expert_pred | 0.72     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.665    |\n",
      "|    disc/disc_acc_expert             | 0.867    |\n",
      "|    disc/disc_acc_gen                | 0.464    |\n",
      "|    disc/disc_entropy                | 0.482    |\n",
      "|    disc/disc_loss                   | 0.607    |\n",
      "|    disc/disc_proportion_expert_pred | 0.701    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.66     |\n",
      "|    disc/disc_acc_expert             | 0.873    |\n",
      "|    disc/disc_acc_gen                | 0.447    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.616    |\n",
      "|    disc/disc_proportion_expert_pred | 0.713    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 15       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.67e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -25.9    |\n",
      "|    gen/time/fps                     | 6.71e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.67     |\n",
      "|    gen/time/total_timesteps         | 3.85e+05 |\n",
      "|    gen/train/approx_kl              | 0.00383  |\n",
      "|    gen/train/clip_fraction          | 0.0475   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.628   |\n",
      "|    gen/train/explained_variance     | 0.104    |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.338    |\n",
      "|    gen/train/n_updates              | 470      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00292 |\n",
      "|    gen/train/value_loss             | 0.803    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:47<00:39,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.62e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -26.5       |\n",
      "|    gen/time/fps                    | 7992        |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 1           |\n",
      "|    gen/time/total_timesteps        | 401408      |\n",
      "|    gen/train/approx_kl             | 0.003811107 |\n",
      "|    gen/train/clip_fraction         | 0.0475      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.607      |\n",
      "|    gen/train/explained_variance    | 0.11        |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.416       |\n",
      "|    gen/train/n_updates             | 480         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00277    |\n",
      "|    gen/train/value_loss            | 0.825       |\n",
      "----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.69e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -28.8       |\n",
      "|    gen/time/fps                    | 4411        |\n",
      "|    gen/time/iterations             | 2           |\n",
      "|    gen/time/time_elapsed           | 3           |\n",
      "|    gen/time/total_timesteps        | 409600      |\n",
      "|    gen/train/approx_kl             | 0.002900138 |\n",
      "|    gen/train/clip_fraction         | 0.0362      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.603      |\n",
      "|    gen/train/explained_variance    | 0.0965      |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.315       |\n",
      "|    gen/train/n_updates             | 490         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00224    |\n",
      "|    gen/train/value_loss            | 0.751       |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.69e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -29.4        |\n",
      "|    gen/time/fps                    | 4154         |\n",
      "|    gen/time/iterations             | 3            |\n",
      "|    gen/time/time_elapsed           | 5            |\n",
      "|    gen/time/total_timesteps        | 417792       |\n",
      "|    gen/train/approx_kl             | 0.0038964604 |\n",
      "|    gen/train/clip_fraction         | 0.0448       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.601       |\n",
      "|    gen/train/explained_variance    | 0.1          |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.378        |\n",
      "|    gen/train/n_updates             | 500          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00298     |\n",
      "|    gen/train/value_loss            | 0.85         |\n",
      "-----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.641    |\n",
      "|    disc/disc_acc_expert             | 0.851    |\n",
      "|    disc/disc_acc_gen                | 0.432    |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.62     |\n",
      "|    disc/disc_proportion_expert_pred | 0.709    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.653    |\n",
      "|    disc/disc_acc_expert             | 0.873    |\n",
      "|    disc/disc_acc_gen                | 0.433    |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.615    |\n",
      "|    disc/disc_proportion_expert_pred | 0.72     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.648    |\n",
      "|    disc/disc_acc_expert             | 0.87     |\n",
      "|    disc/disc_acc_gen                | 0.427    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.641    |\n",
      "|    disc/disc_proportion_expert_pred | 0.722    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.657    |\n",
      "|    disc/disc_acc_expert             | 0.872    |\n",
      "|    disc/disc_acc_gen                | 0.442    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.615    |\n",
      "|    disc/disc_proportion_expert_pred | 0.715    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.647    |\n",
      "|    disc/disc_acc_expert             | 0.87     |\n",
      "|    disc/disc_acc_gen                | 0.424    |\n",
      "|    disc/disc_entropy                | 0.483    |\n",
      "|    disc/disc_loss                   | 0.627    |\n",
      "|    disc/disc_proportion_expert_pred | 0.723    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.649    |\n",
      "|    disc/disc_acc_expert             | 0.872    |\n",
      "|    disc/disc_acc_gen                | 0.427    |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.614    |\n",
      "|    disc/disc_proportion_expert_pred | 0.722    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.677    |\n",
      "|    disc/disc_acc_expert             | 0.888    |\n",
      "|    disc/disc_acc_gen                | 0.465    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.594    |\n",
      "|    disc/disc_proportion_expert_pred | 0.711    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.647    |\n",
      "|    disc/disc_acc_expert             | 0.865    |\n",
      "|    disc/disc_acc_gen                | 0.429    |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.626    |\n",
      "|    disc/disc_proportion_expert_pred | 0.718    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.656    |\n",
      "|    disc/disc_acc_expert             | 0.876    |\n",
      "|    disc/disc_acc_gen                | 0.435    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.623    |\n",
      "|    disc/disc_proportion_expert_pred | 0.721    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.651    |\n",
      "|    disc/disc_acc_expert             | 0.88     |\n",
      "|    disc/disc_acc_gen                | 0.421    |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.615    |\n",
      "|    disc/disc_proportion_expert_pred | 0.729    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.671    |\n",
      "|    disc/disc_acc_expert             | 0.886    |\n",
      "|    disc/disc_acc_gen                | 0.455    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.605    |\n",
      "|    disc/disc_proportion_expert_pred | 0.716    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.655    |\n",
      "|    disc/disc_acc_expert             | 0.872    |\n",
      "|    disc/disc_acc_gen                | 0.438    |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.61     |\n",
      "|    disc/disc_proportion_expert_pred | 0.717    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.658    |\n",
      "|    disc/disc_acc_expert             | 0.87     |\n",
      "|    disc/disc_acc_gen                | 0.445    |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.627    |\n",
      "|    disc/disc_proportion_expert_pred | 0.712    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.648    |\n",
      "|    disc/disc_acc_expert             | 0.873    |\n",
      "|    disc/disc_acc_gen                | 0.424    |\n",
      "|    disc/disc_entropy                | 0.48     |\n",
      "|    disc/disc_loss                   | 0.617    |\n",
      "|    disc/disc_proportion_expert_pred | 0.725    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.642    |\n",
      "|    disc/disc_acc_expert             | 0.875    |\n",
      "|    disc/disc_acc_gen                | 0.409    |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.632    |\n",
      "|    disc/disc_proportion_expert_pred | 0.733    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.658    |\n",
      "|    disc/disc_acc_expert             | 0.881    |\n",
      "|    disc/disc_acc_gen                | 0.435    |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.608    |\n",
      "|    disc/disc_proportion_expert_pred | 0.723    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.654    |\n",
      "|    disc/disc_acc_expert             | 0.873    |\n",
      "|    disc/disc_acc_gen                | 0.434    |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.618    |\n",
      "|    disc/disc_proportion_expert_pred | 0.72     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 16       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.67e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -28.2    |\n",
      "|    gen/time/fps                     | 5.52e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 3        |\n",
      "|    gen/time/total_timesteps         | 4.1e+05  |\n",
      "|    gen/train/approx_kl              | 0.00341  |\n",
      "|    gen/train/clip_fraction          | 0.0418   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.601   |\n",
      "|    gen/train/explained_variance     | 0.1      |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.319    |\n",
      "|    gen/train/n_updates              | 500      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00259 |\n",
      "|    gen/train/value_loss             | 0.789    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [01:54<00:31,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.7e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -29.5       |\n",
      "|    gen/time/fps                    | 9795        |\n",
      "|    gen/time/iterations             | 1           |\n",
      "|    gen/time/time_elapsed           | 0           |\n",
      "|    gen/time/total_timesteps        | 425984      |\n",
      "|    gen/train/approx_kl             | 0.003427391 |\n",
      "|    gen/train/clip_fraction         | 0.0443      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.598      |\n",
      "|    gen/train/explained_variance    | 0.104       |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.264       |\n",
      "|    gen/train/n_updates             | 510         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00255    |\n",
      "|    gen/train/value_loss            | 0.767       |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.72e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -31          |\n",
      "|    gen/time/fps                    | 5359         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 3            |\n",
      "|    gen/time/total_timesteps        | 434176       |\n",
      "|    gen/train/approx_kl             | 0.0033055502 |\n",
      "|    gen/train/clip_fraction         | 0.0353       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.579       |\n",
      "|    gen/train/explained_variance    | 0.101        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.458        |\n",
      "|    gen/train/n_updates             | 520          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00188     |\n",
      "|    gen/train/value_loss            | 0.803        |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.68e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -32          |\n",
      "|    gen/time/fps                    | 4407         |\n",
      "|    gen/time/iterations             | 3            |\n",
      "|    gen/time/time_elapsed           | 5            |\n",
      "|    gen/time/total_timesteps        | 442368       |\n",
      "|    gen/train/approx_kl             | 0.0032708882 |\n",
      "|    gen/train/clip_fraction         | 0.0421       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.566       |\n",
      "|    gen/train/explained_variance    | 0.101        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.355        |\n",
      "|    gen/train/n_updates             | 530          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00249     |\n",
      "|    gen/train/value_loss            | 0.778        |\n",
      "-----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.712    |\n",
      "|    disc/disc_acc_expert             | 0.837    |\n",
      "|    disc/disc_acc_gen                | 0.588    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.593    |\n",
      "|    disc/disc_proportion_expert_pred | 0.625    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.697    |\n",
      "|    disc/disc_acc_expert             | 0.815    |\n",
      "|    disc/disc_acc_gen                | 0.578    |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.612    |\n",
      "|    disc/disc_proportion_expert_pred | 0.618    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.702    |\n",
      "|    disc/disc_acc_expert             | 0.824    |\n",
      "|    disc/disc_acc_gen                | 0.58     |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.609    |\n",
      "|    disc/disc_proportion_expert_pred | 0.622    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.703    |\n",
      "|    disc/disc_acc_expert             | 0.821    |\n",
      "|    disc/disc_acc_gen                | 0.584    |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.595    |\n",
      "|    disc/disc_proportion_expert_pred | 0.619    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.702    |\n",
      "|    disc/disc_acc_expert             | 0.832    |\n",
      "|    disc/disc_acc_gen                | 0.571    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.594    |\n",
      "|    disc/disc_proportion_expert_pred | 0.63     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.712    |\n",
      "|    disc/disc_acc_expert             | 0.824    |\n",
      "|    disc/disc_acc_gen                | 0.6      |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.586    |\n",
      "|    disc/disc_proportion_expert_pred | 0.612    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.713    |\n",
      "|    disc/disc_acc_expert             | 0.843    |\n",
      "|    disc/disc_acc_gen                | 0.583    |\n",
      "|    disc/disc_entropy                | 0.467    |\n",
      "|    disc/disc_loss                   | 0.602    |\n",
      "|    disc/disc_proportion_expert_pred | 0.63     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.704    |\n",
      "|    disc/disc_acc_expert             | 0.821    |\n",
      "|    disc/disc_acc_gen                | 0.587    |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.596    |\n",
      "|    disc/disc_proportion_expert_pred | 0.617    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.699    |\n",
      "|    disc/disc_acc_expert             | 0.831    |\n",
      "|    disc/disc_acc_gen                | 0.566    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.605    |\n",
      "|    disc/disc_proportion_expert_pred | 0.632    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.699    |\n",
      "|    disc/disc_acc_expert             | 0.831    |\n",
      "|    disc/disc_acc_gen                | 0.568    |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.609    |\n",
      "|    disc/disc_proportion_expert_pred | 0.631    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.691    |\n",
      "|    disc/disc_acc_expert             | 0.825    |\n",
      "|    disc/disc_acc_gen                | 0.557    |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.608    |\n",
      "|    disc/disc_proportion_expert_pred | 0.634    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.699    |\n",
      "|    disc/disc_acc_expert             | 0.817    |\n",
      "|    disc/disc_acc_gen                | 0.581    |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.594    |\n",
      "|    disc/disc_proportion_expert_pred | 0.618    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.701    |\n",
      "|    disc/disc_acc_expert             | 0.827    |\n",
      "|    disc/disc_acc_gen                | 0.576    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.596    |\n",
      "|    disc/disc_proportion_expert_pred | 0.625    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.706    |\n",
      "|    disc/disc_acc_expert             | 0.829    |\n",
      "|    disc/disc_acc_gen                | 0.584    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.602    |\n",
      "|    disc/disc_proportion_expert_pred | 0.622    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.705    |\n",
      "|    disc/disc_acc_expert             | 0.837    |\n",
      "|    disc/disc_acc_gen                | 0.573    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.587    |\n",
      "|    disc/disc_proportion_expert_pred | 0.632    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.714    |\n",
      "|    disc/disc_acc_expert             | 0.852    |\n",
      "|    disc/disc_acc_gen                | 0.576    |\n",
      "|    disc/disc_entropy                | 0.469    |\n",
      "|    disc/disc_loss                   | 0.591    |\n",
      "|    disc/disc_proportion_expert_pred | 0.638    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.704    |\n",
      "|    disc/disc_acc_expert             | 0.829    |\n",
      "|    disc/disc_acc_gen                | 0.578    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.599    |\n",
      "|    disc/disc_proportion_expert_pred | 0.625    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 17       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.7e+03  |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -30.8    |\n",
      "|    gen/time/fps                     | 6.52e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.67     |\n",
      "|    gen/time/total_timesteps         | 4.34e+05 |\n",
      "|    gen/train/approx_kl              | 0.0033   |\n",
      "|    gen/train/clip_fraction          | 0.0396   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.564   |\n",
      "|    gen/train/explained_variance     | 0.103    |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.354    |\n",
      "|    gen/train/n_updates              | 530      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00211 |\n",
      "|    gen/train/value_loss             | 0.772    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [02:02<00:23,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -31.7        |\n",
      "|    gen/time/fps                    | 10159        |\n",
      "|    gen/time/iterations             | 1            |\n",
      "|    gen/time/time_elapsed           | 0            |\n",
      "|    gen/time/total_timesteps        | 450560       |\n",
      "|    gen/train/approx_kl             | 0.0033179338 |\n",
      "|    gen/train/clip_fraction         | 0.0414       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.545       |\n",
      "|    gen/train/explained_variance    | 0.106        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.248        |\n",
      "|    gen/train/n_updates             | 540          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00195     |\n",
      "|    gen/train/value_loss            | 0.734        |\n",
      "-----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.71e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -33.6       |\n",
      "|    gen/time/fps                    | 5387        |\n",
      "|    gen/time/iterations             | 2           |\n",
      "|    gen/time/time_elapsed           | 3           |\n",
      "|    gen/time/total_timesteps        | 458752      |\n",
      "|    gen/train/approx_kl             | 0.002228938 |\n",
      "|    gen/train/clip_fraction         | 0.0343      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.54       |\n",
      "|    gen/train/explained_variance    | 0.105       |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.451       |\n",
      "|    gen/train/n_updates             | 550         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00204    |\n",
      "|    gen/train/value_loss            | 0.782       |\n",
      "----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.7e+03      |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -34.3        |\n",
      "|    gen/time/fps                    | 4751         |\n",
      "|    gen/time/iterations             | 3            |\n",
      "|    gen/time/time_elapsed           | 5            |\n",
      "|    gen/time/total_timesteps        | 466944       |\n",
      "|    gen/train/approx_kl             | 0.0027636401 |\n",
      "|    gen/train/clip_fraction         | 0.0363       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.509       |\n",
      "|    gen/train/explained_variance    | 0.106        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.355        |\n",
      "|    gen/train/n_updates             | 560          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00228     |\n",
      "|    gen/train/value_loss            | 0.787        |\n",
      "-----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.739    |\n",
      "|    disc/disc_acc_expert             | 0.794    |\n",
      "|    disc/disc_acc_gen                | 0.683    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.586    |\n",
      "|    disc/disc_proportion_expert_pred | 0.555    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.752    |\n",
      "|    disc/disc_acc_expert             | 0.792    |\n",
      "|    disc/disc_acc_gen                | 0.713    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.575    |\n",
      "|    disc/disc_proportion_expert_pred | 0.539    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.74     |\n",
      "|    disc/disc_acc_expert             | 0.792    |\n",
      "|    disc/disc_acc_gen                | 0.688    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.575    |\n",
      "|    disc/disc_proportion_expert_pred | 0.552    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.75     |\n",
      "|    disc/disc_acc_expert             | 0.816    |\n",
      "|    disc/disc_acc_gen                | 0.684    |\n",
      "|    disc/disc_entropy                | 0.465    |\n",
      "|    disc/disc_loss                   | 0.575    |\n",
      "|    disc/disc_proportion_expert_pred | 0.566    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.745    |\n",
      "|    disc/disc_acc_expert             | 0.792    |\n",
      "|    disc/disc_acc_gen                | 0.697    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.57     |\n",
      "|    disc/disc_proportion_expert_pred | 0.548    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.74     |\n",
      "|    disc/disc_acc_expert             | 0.801    |\n",
      "|    disc/disc_acc_gen                | 0.68     |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.569    |\n",
      "|    disc/disc_proportion_expert_pred | 0.561    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.753    |\n",
      "|    disc/disc_acc_expert             | 0.793    |\n",
      "|    disc/disc_acc_gen                | 0.713    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.553    |\n",
      "|    disc/disc_proportion_expert_pred | 0.54     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.746    |\n",
      "|    disc/disc_acc_expert             | 0.796    |\n",
      "|    disc/disc_acc_gen                | 0.696    |\n",
      "|    disc/disc_entropy                | 0.479    |\n",
      "|    disc/disc_loss                   | 0.556    |\n",
      "|    disc/disc_proportion_expert_pred | 0.55     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.743    |\n",
      "|    disc/disc_acc_expert             | 0.789    |\n",
      "|    disc/disc_acc_gen                | 0.697    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.576    |\n",
      "|    disc/disc_proportion_expert_pred | 0.546    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.744    |\n",
      "|    disc/disc_acc_expert             | 0.794    |\n",
      "|    disc/disc_acc_gen                | 0.694    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.563    |\n",
      "|    disc/disc_proportion_expert_pred | 0.55     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.75     |\n",
      "|    disc/disc_acc_expert             | 0.803    |\n",
      "|    disc/disc_acc_gen                | 0.698    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.559    |\n",
      "|    disc/disc_proportion_expert_pred | 0.552    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.739    |\n",
      "|    disc/disc_acc_expert             | 0.78     |\n",
      "|    disc/disc_acc_gen                | 0.697    |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.576    |\n",
      "|    disc/disc_proportion_expert_pred | 0.542    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.752    |\n",
      "|    disc/disc_acc_expert             | 0.804    |\n",
      "|    disc/disc_acc_gen                | 0.701    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.561    |\n",
      "|    disc/disc_proportion_expert_pred | 0.552    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.746    |\n",
      "|    disc/disc_acc_expert             | 0.785    |\n",
      "|    disc/disc_acc_gen                | 0.708    |\n",
      "|    disc/disc_entropy                | 0.478    |\n",
      "|    disc/disc_loss                   | 0.564    |\n",
      "|    disc/disc_proportion_expert_pred | 0.538    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.757    |\n",
      "|    disc/disc_acc_expert             | 0.812    |\n",
      "|    disc/disc_acc_gen                | 0.702    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.558    |\n",
      "|    disc/disc_proportion_expert_pred | 0.555    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.75     |\n",
      "|    disc/disc_acc_expert             | 0.786    |\n",
      "|    disc/disc_acc_gen                | 0.713    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.571    |\n",
      "|    disc/disc_proportion_expert_pred | 0.536    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.747    |\n",
      "|    disc/disc_acc_expert             | 0.796    |\n",
      "|    disc/disc_acc_gen                | 0.698    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.568    |\n",
      "|    disc/disc_proportion_expert_pred | 0.549    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 18       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.71e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -33.2    |\n",
      "|    gen/time/fps                     | 6.77e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.67     |\n",
      "|    gen/time/total_timesteps         | 4.59e+05 |\n",
      "|    gen/train/approx_kl              | 0.0025   |\n",
      "|    gen/train/clip_fraction          | 0.0359   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.515   |\n",
      "|    gen/train/explained_variance     | 0.106    |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.453    |\n",
      "|    gen/train/n_updates              | 560      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00216 |\n",
      "|    gen/train/value_loss             | 0.816    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [02:09<00:14,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.75e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -34.3        |\n",
      "|    gen/time/fps                    | 10734        |\n",
      "|    gen/time/iterations             | 1            |\n",
      "|    gen/time/time_elapsed           | 0            |\n",
      "|    gen/time/total_timesteps        | 475136       |\n",
      "|    gen/train/approx_kl             | 0.0025103237 |\n",
      "|    gen/train/clip_fraction         | 0.0372       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.494       |\n",
      "|    gen/train/explained_variance    | 0.108        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.555        |\n",
      "|    gen/train/n_updates             | 570          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00214     |\n",
      "|    gen/train/value_loss            | 0.879        |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.65e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -35.8        |\n",
      "|    gen/time/fps                    | 5842         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 2            |\n",
      "|    gen/time/total_timesteps        | 483328       |\n",
      "|    gen/train/approx_kl             | 0.0023939991 |\n",
      "|    gen/train/clip_fraction         | 0.0325       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.467       |\n",
      "|    gen/train/explained_variance    | 0.0935       |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.411        |\n",
      "|    gen/train/n_updates             | 580          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00145     |\n",
      "|    gen/train/value_loss            | 0.694        |\n",
      "-----------------------------------------------------\n",
      "----------------------------------------------------\n",
      "| raw/                               |             |\n",
      "|    gen/rollout/ep_len_mean         | 100         |\n",
      "|    gen/rollout/ep_rew_mean         | 4.67e+03    |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -36         |\n",
      "|    gen/time/fps                    | 5071        |\n",
      "|    gen/time/iterations             | 3           |\n",
      "|    gen/time/time_elapsed           | 4           |\n",
      "|    gen/time/total_timesteps        | 491520      |\n",
      "|    gen/train/approx_kl             | 0.002684235 |\n",
      "|    gen/train/clip_fraction         | 0.0371      |\n",
      "|    gen/train/clip_range            | 0.2         |\n",
      "|    gen/train/entropy_loss          | -0.458      |\n",
      "|    gen/train/explained_variance    | 0.106       |\n",
      "|    gen/train/learning_rate         | 0.0003      |\n",
      "|    gen/train/loss                  | 0.324       |\n",
      "|    gen/train/n_updates             | 590         |\n",
      "|    gen/train/policy_gradient_loss  | -0.00247    |\n",
      "|    gen/train/value_loss            | 0.652       |\n",
      "----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.76     |\n",
      "|    disc/disc_acc_expert             | 0.801    |\n",
      "|    disc/disc_acc_gen                | 0.72     |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.532    |\n",
      "|    disc/disc_proportion_expert_pred | 0.541    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.767    |\n",
      "|    disc/disc_acc_expert             | 0.805    |\n",
      "|    disc/disc_acc_gen                | 0.729    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.523    |\n",
      "|    disc/disc_proportion_expert_pred | 0.538    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.766    |\n",
      "|    disc/disc_acc_expert             | 0.804    |\n",
      "|    disc/disc_acc_gen                | 0.729    |\n",
      "|    disc/disc_entropy                | 0.469    |\n",
      "|    disc/disc_loss                   | 0.516    |\n",
      "|    disc/disc_proportion_expert_pred | 0.537    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.757    |\n",
      "|    disc/disc_acc_expert             | 0.812    |\n",
      "|    disc/disc_acc_gen                | 0.702    |\n",
      "|    disc/disc_entropy                | 0.465    |\n",
      "|    disc/disc_loss                   | 0.521    |\n",
      "|    disc/disc_proportion_expert_pred | 0.555    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.763    |\n",
      "|    disc/disc_acc_expert             | 0.8      |\n",
      "|    disc/disc_acc_gen                | 0.727    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.521    |\n",
      "|    disc/disc_proportion_expert_pred | 0.537    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.752    |\n",
      "|    disc/disc_acc_expert             | 0.795    |\n",
      "|    disc/disc_acc_gen                | 0.708    |\n",
      "|    disc/disc_entropy                | 0.47     |\n",
      "|    disc/disc_loss                   | 0.527    |\n",
      "|    disc/disc_proportion_expert_pred | 0.543    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.762    |\n",
      "|    disc/disc_acc_expert             | 0.812    |\n",
      "|    disc/disc_acc_gen                | 0.713    |\n",
      "|    disc/disc_entropy                | 0.468    |\n",
      "|    disc/disc_loss                   | 0.532    |\n",
      "|    disc/disc_proportion_expert_pred | 0.549    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.753    |\n",
      "|    disc/disc_acc_expert             | 0.795    |\n",
      "|    disc/disc_acc_gen                | 0.711    |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.527    |\n",
      "|    disc/disc_proportion_expert_pred | 0.542    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.769    |\n",
      "|    disc/disc_acc_expert             | 0.804    |\n",
      "|    disc/disc_acc_gen                | 0.733    |\n",
      "|    disc/disc_entropy                | 0.469    |\n",
      "|    disc/disc_loss                   | 0.511    |\n",
      "|    disc/disc_proportion_expert_pred | 0.536    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.75     |\n",
      "|    disc/disc_acc_expert             | 0.774    |\n",
      "|    disc/disc_acc_gen                | 0.726    |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.53     |\n",
      "|    disc/disc_proportion_expert_pred | 0.524    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.751    |\n",
      "|    disc/disc_acc_expert             | 0.797    |\n",
      "|    disc/disc_acc_gen                | 0.706    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.523    |\n",
      "|    disc/disc_proportion_expert_pred | 0.545    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.746    |\n",
      "|    disc/disc_acc_expert             | 0.786    |\n",
      "|    disc/disc_acc_gen                | 0.705    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.534    |\n",
      "|    disc/disc_proportion_expert_pred | 0.541    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.752    |\n",
      "|    disc/disc_acc_expert             | 0.803    |\n",
      "|    disc/disc_acc_gen                | 0.7      |\n",
      "|    disc/disc_entropy                | 0.465    |\n",
      "|    disc/disc_loss                   | 0.533    |\n",
      "|    disc/disc_proportion_expert_pred | 0.552    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.752    |\n",
      "|    disc/disc_acc_expert             | 0.792    |\n",
      "|    disc/disc_acc_gen                | 0.712    |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.525    |\n",
      "|    disc/disc_proportion_expert_pred | 0.54     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.757    |\n",
      "|    disc/disc_acc_expert             | 0.792    |\n",
      "|    disc/disc_acc_gen                | 0.723    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.522    |\n",
      "|    disc/disc_proportion_expert_pred | 0.534    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.757    |\n",
      "|    disc/disc_acc_expert             | 0.8      |\n",
      "|    disc/disc_acc_gen                | 0.714    |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.518    |\n",
      "|    disc/disc_proportion_expert_pred | 0.543    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.757    |\n",
      "|    disc/disc_acc_expert             | 0.798    |\n",
      "|    disc/disc_acc_gen                | 0.716    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.525    |\n",
      "|    disc/disc_proportion_expert_pred | 0.541    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 19       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.69e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -35.4    |\n",
      "|    gen/time/fps                     | 7.22e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2        |\n",
      "|    gen/time/total_timesteps         | 4.83e+05 |\n",
      "|    gen/train/approx_kl              | 0.00244  |\n",
      "|    gen/train/clip_fraction          | 0.036    |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.457   |\n",
      "|    gen/train/explained_variance     | 0.102    |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.368    |\n",
      "|    gen/train/n_updates              | 590      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00204 |\n",
      "|    gen/train/value_loss             | 0.672    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [02:15<00:07,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.73e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -36.1        |\n",
      "|    gen/time/fps                    | 11077        |\n",
      "|    gen/time/iterations             | 1            |\n",
      "|    gen/time/time_elapsed           | 0            |\n",
      "|    gen/time/total_timesteps        | 499712       |\n",
      "|    gen/train/approx_kl             | 0.0022415079 |\n",
      "|    gen/train/clip_fraction         | 0.0385       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.446       |\n",
      "|    gen/train/explained_variance    | 0.107        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.368        |\n",
      "|    gen/train/n_updates             | 600          |\n",
      "|    gen/train/policy_gradient_loss  | -0.0022      |\n",
      "|    gen/train/value_loss            | 0.67         |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.73e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -37.6        |\n",
      "|    gen/time/fps                    | 5946         |\n",
      "|    gen/time/iterations             | 2            |\n",
      "|    gen/time/time_elapsed           | 2            |\n",
      "|    gen/time/total_timesteps        | 507904       |\n",
      "|    gen/train/approx_kl             | 0.0016667526 |\n",
      "|    gen/train/clip_fraction         | 0.0227       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.434       |\n",
      "|    gen/train/explained_variance    | 0.104        |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.291        |\n",
      "|    gen/train/n_updates             | 610          |\n",
      "|    gen/train/policy_gradient_loss  | -0.000651    |\n",
      "|    gen/train/value_loss            | 0.721        |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                               |              |\n",
      "|    gen/rollout/ep_len_mean         | 100          |\n",
      "|    gen/rollout/ep_rew_mean         | 4.74e+03     |\n",
      "|    gen/rollout/ep_rew_wrapped_mean | -37.9        |\n",
      "|    gen/time/fps                    | 4708         |\n",
      "|    gen/time/iterations             | 3            |\n",
      "|    gen/time/time_elapsed           | 5            |\n",
      "|    gen/time/total_timesteps        | 516096       |\n",
      "|    gen/train/approx_kl             | 0.0022618154 |\n",
      "|    gen/train/clip_fraction         | 0.0356       |\n",
      "|    gen/train/clip_range            | 0.2          |\n",
      "|    gen/train/entropy_loss          | -0.421       |\n",
      "|    gen/train/explained_variance    | 0.11         |\n",
      "|    gen/train/learning_rate         | 0.0003       |\n",
      "|    gen/train/loss                  | 0.344        |\n",
      "|    gen/train/n_updates             | 620          |\n",
      "|    gen/train/policy_gradient_loss  | -0.00244     |\n",
      "|    gen/train/value_loss            | 0.786        |\n",
      "-----------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.76     |\n",
      "|    disc/disc_acc_expert             | 0.766    |\n",
      "|    disc/disc_acc_gen                | 0.754    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.527    |\n",
      "|    disc/disc_proportion_expert_pred | 0.506    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.773    |\n",
      "|    disc/disc_acc_expert             | 0.779    |\n",
      "|    disc/disc_acc_gen                | 0.768    |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.507    |\n",
      "|    disc/disc_proportion_expert_pred | 0.506    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.754    |\n",
      "|    disc/disc_acc_expert             | 0.781    |\n",
      "|    disc/disc_acc_gen                | 0.727    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.523    |\n",
      "|    disc/disc_proportion_expert_pred | 0.527    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.766    |\n",
      "|    disc/disc_acc_expert             | 0.79     |\n",
      "|    disc/disc_acc_gen                | 0.742    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.523    |\n",
      "|    disc/disc_proportion_expert_pred | 0.524    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.775    |\n",
      "|    disc/disc_acc_expert             | 0.785    |\n",
      "|    disc/disc_acc_gen                | 0.765    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.506    |\n",
      "|    disc/disc_proportion_expert_pred | 0.51     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.771    |\n",
      "|    disc/disc_acc_expert             | 0.779    |\n",
      "|    disc/disc_acc_gen                | 0.764    |\n",
      "|    disc/disc_entropy                | 0.473    |\n",
      "|    disc/disc_loss                   | 0.526    |\n",
      "|    disc/disc_proportion_expert_pred | 0.508    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.767    |\n",
      "|    disc/disc_acc_expert             | 0.779    |\n",
      "|    disc/disc_acc_gen                | 0.754    |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.506    |\n",
      "|    disc/disc_proportion_expert_pred | 0.512    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.768    |\n",
      "|    disc/disc_acc_expert             | 0.771    |\n",
      "|    disc/disc_acc_gen                | 0.765    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.522    |\n",
      "|    disc/disc_proportion_expert_pred | 0.503    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.769    |\n",
      "|    disc/disc_acc_expert             | 0.786    |\n",
      "|    disc/disc_acc_gen                | 0.752    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.509    |\n",
      "|    disc/disc_proportion_expert_pred | 0.517    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.764    |\n",
      "|    disc/disc_acc_expert             | 0.772    |\n",
      "|    disc/disc_acc_gen                | 0.757    |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.518    |\n",
      "|    disc/disc_proportion_expert_pred | 0.508    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.76     |\n",
      "|    disc/disc_acc_expert             | 0.78     |\n",
      "|    disc/disc_acc_gen                | 0.739    |\n",
      "|    disc/disc_entropy                | 0.471    |\n",
      "|    disc/disc_loss                   | 0.525    |\n",
      "|    disc/disc_proportion_expert_pred | 0.521    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.77     |\n",
      "|    disc/disc_acc_expert             | 0.777    |\n",
      "|    disc/disc_acc_gen                | 0.762    |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.518    |\n",
      "|    disc/disc_proportion_expert_pred | 0.507    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.762    |\n",
      "|    disc/disc_acc_expert             | 0.784    |\n",
      "|    disc/disc_acc_gen                | 0.741    |\n",
      "|    disc/disc_entropy                | 0.472    |\n",
      "|    disc/disc_loss                   | 0.516    |\n",
      "|    disc/disc_proportion_expert_pred | 0.521    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.766    |\n",
      "|    disc/disc_acc_expert             | 0.771    |\n",
      "|    disc/disc_acc_gen                | 0.76     |\n",
      "|    disc/disc_entropy                | 0.475    |\n",
      "|    disc/disc_loss                   | 0.513    |\n",
      "|    disc/disc_proportion_expert_pred | 0.506    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.762    |\n",
      "|    disc/disc_acc_expert             | 0.77     |\n",
      "|    disc/disc_acc_gen                | 0.755    |\n",
      "|    disc/disc_entropy                | 0.477    |\n",
      "|    disc/disc_loss                   | 0.511    |\n",
      "|    disc/disc_proportion_expert_pred | 0.507    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.762    |\n",
      "|    disc/disc_acc_expert             | 0.776    |\n",
      "|    disc/disc_acc_gen                | 0.748    |\n",
      "|    disc/disc_entropy                | 0.476    |\n",
      "|    disc/disc_loss                   | 0.518    |\n",
      "|    disc/disc_proportion_expert_pred | 0.514    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| mean/                               |          |\n",
      "|    disc/disc_acc                    | 0.766    |\n",
      "|    disc/disc_acc_expert             | 0.778    |\n",
      "|    disc/disc_acc_gen                | 0.753    |\n",
      "|    disc/disc_entropy                | 0.474    |\n",
      "|    disc/disc_loss                   | 0.517    |\n",
      "|    disc/disc_proportion_expert_pred | 0.512    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 20       |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "|    gen/rollout/ep_len_mean          | 100      |\n",
      "|    gen/rollout/ep_rew_mean          | 4.73e+03 |\n",
      "|    gen/rollout/ep_rew_wrapped_mean  | -37.2    |\n",
      "|    gen/time/fps                     | 7.24e+03 |\n",
      "|    gen/time/iterations              | 2        |\n",
      "|    gen/time/time_elapsed            | 2.33     |\n",
      "|    gen/time/total_timesteps         | 5.08e+05 |\n",
      "|    gen/train/approx_kl              | 0.00195  |\n",
      "|    gen/train/clip_fraction          | 0.0305   |\n",
      "|    gen/train/clip_range             | 0.2      |\n",
      "|    gen/train/entropy_loss           | -0.426   |\n",
      "|    gen/train/explained_variance     | 0.105    |\n",
      "|    gen/train/learning_rate          | 0.0003   |\n",
      "|    gen/train/loss                   | 0.359    |\n",
      "|    gen/train/n_updates              | 620      |\n",
      "|    gen/train/policy_gradient_loss   | -0.00159 |\n",
      "|    gen/train/value_loss             | 0.719    |\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [02:22<00:00,  7.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards before training: [4768.710115, 4692.632661, 4869.663429, 4784.441342, 4545.624197, 4428.667949, 4534.754933, 4713.298339, 4764.056606, 3870.04105, 4911.166673, 4420.958159, 5799.934528, 5004.778598, 5026.814824, 4017.348386, 4773.924581, 4207.680165, 5264.951371, 5377.535353, 4624.131204, 4270.633714, 4603.282079, 4743.720706, 4941.311618, 4891.641531, 4385.264596, 5191.852421, 5083.66841, 4733.089949, 4505.029009, 4300.593913, 4935.688861, 4909.506509, 4542.052414, 5269.351496, 5124.718136, 3979.485401, 5243.085019, 4626.234915, 5466.679829, 4788.53652, 4898.127843, 4685.616203, 4635.893149, 3908.566627, 4695.442003, 4845.485937, 5342.25892, 4394.702881, 4623.211026, 4935.420394, 5208.647175, 4691.422595, 4873.151505, 4317.530833, 5060.209517, 4473.888249, 4759.913742, 4984.560705, 5227.746115, 4352.277946, 4597.445216, 5539.130039, 4658.579698, 4499.066206, 4828.247455, 5087.109284, 5107.076415, 4944.104384, 4679.261463, 4807.64509, 4011.939786, 4426.38132, 4252.59888, 4966.410213, 4703.379923, 4341.277405, 5077.676226, 4507.214494, 5088.981571, 3867.562794, 4954.6257, 4509.775958, 5190.625898, 4574.246282, 4351.344167, 4575.895706, 5002.147782, 4763.921715, 4789.188089, 4678.006625, 5213.944889, 4756.478215, 4142.578391, 5024.828629, 4804.609845, 4160.23386, 4930.938313, 4580.634514]\n",
      "Rewards after training: [4878.183535, 4032.451384, 4753.212807, 4064.20778, 5262.36502, 4374.026528, 4297.496464, 5123.270482, 4523.581298, 5148.976398, 5182.419067, 4188.623988, 5376.00415, 4874.478152, 4985.948095, 5099.862305, 4764.917752, 4649.090391, 5513.807814, 4501.356623, 5096.710433, 4765.395343, 4857.048669, 4460.548688, 4735.388787, 4703.864198, 4203.889423, 3999.772505, 4843.825845, 4208.041658, 4037.91617, 4008.812247, 5159.157667, 4669.217649, 4686.837485, 4659.051198, 5012.094967, 4649.347763, 5015.501271, 4522.410834, 4853.962651, 4968.86747, 4785.550844, 4747.892569, 4925.848173, 4497.787415, 4474.041646, 4768.860867, 4701.213124, 4184.014544, 4945.960539, 5033.262006, 4883.431685, 4755.334766, 4900.43332, 4742.615448, 4640.467979, 5523.280977, 4491.230914, 5288.342414, 4786.271881, 4985.046065, 4205.576395, 5324.574418, 5116.113612, 4890.314037, 4934.497211, 4656.835202, 5131.696518, 4749.295078, 4581.648467, 4871.35901, 4887.814036, 4531.389414, 4661.027598, 4715.254243, 4827.327622, 4277.535675, 4748.100074, 4354.372994, 5092.418041, 3907.174099, 4681.487048, 4623.223859, 4501.681397, 4986.063432, 4373.057178, 4437.556937, 5096.106806, 4718.234138, 4836.512989, 4796.057316, 4284.529471, 4928.636573, 4183.243833, 4350.896592, 5038.58591, 4474.847574, 4513.096219, 4420.584803]\n",
      "Mean Rewards before training: 4738.457273139999\n",
      "Mean Rewards after training: 4714.81555949\n"
     ]
    }
   ],
   "source": [
    "venv.seed(SEED)\n",
    "learner_rewards_before_training, _ = evaluate_policy(airl_trainer.gen_algo, venv, 100, return_episode_rewards=True)\n",
    "\n",
    "# Train AIRL\n",
    "airl_trainer.train(total_timesteps=400000)\n",
    "venv.seed(SEED)\n",
    "\n",
    "# Evaluate policy after training\n",
    "learner_rewards_after_training, _ = evaluate_policy(airl_trainer.gen_algo, venv, 100, return_episode_rewards=True)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Rewards before training:\", learner_rewards_before_training)\n",
    "print(\"Rewards after training:\", learner_rewards_after_training)\n",
    "\n",
    "print(\"Mean Rewards before training:\", np.mean(learner_rewards_before_training))\n",
    "print(\"Mean Rewards after training:\", np.mean(learner_rewards_after_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding MSE and MAE over Individual State-Action Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, reward_net, weights, num_samples=100):\n",
    "    true_rewards = []\n",
    "    learned_rewards = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Sample a discrete state and action from the environment\n",
    "        state = env.observation_space.sample()  \n",
    "        action = env.action_space.sample()   \n",
    "\n",
    "        # Compute true reward based on the state's corresponding weight\n",
    "        true_reward = weights[state]  \n",
    "        print(f\"TRUE REWARD = {true_reward}\")\n",
    "        true_rewards.append(true_reward)\n",
    "\n",
    "        # Convert state to one-hot encoded tensor\n",
    "        num_states = env.observation_space.n  # Number of discrete states\n",
    "        state_one_hot = np.zeros(num_states)\n",
    "        state_one_hot[state] = 1\n",
    "        state_tensor = th.FloatTensor(state_one_hot).unsqueeze(0)  \n",
    "\n",
    "        # Convert action to one-hot encoded tensor\n",
    "        num_actions = env.action_space.n  # Number of discrete actions\n",
    "        action_one_hot = np.zeros(num_actions)\n",
    "        action_one_hot[action] = 1\n",
    "        action_tensor = th.FloatTensor(action_one_hot).unsqueeze(0)  \n",
    "\n",
    "        # Compute learned reward using the reward network\n",
    "        learned_reward = reward_net(state_tensor, action_tensor, None, None).item()\n",
    "        print(f\"LEARNED REWARD = {learned_reward}\")\n",
    "        learned_rewards.append(learned_reward)\n",
    "\n",
    "    # Convert rewards to tensors for calculation\n",
    "    true_rewards_tensor = th.tensor(true_rewards, dtype=th.float32)\n",
    "    learned_rewards_tensor = th.tensor(learned_rewards, dtype=th.float32)\n",
    "\n",
    "    print(\"True rewards:\", true_rewards_tensor)\n",
    "    print(\"Learned rewards:\", learned_rewards_tensor)\n",
    "    \n",
    "    # Calculate Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
    "    mae = th.mean(th.abs(true_rewards_tensor - learned_rewards_tensor)).item()\n",
    "    mse = th.mean((true_rewards_tensor - learned_rewards_tensor) ** 2).item()\n",
    "    return mse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 18.34045098534338\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 15.601864044243651\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 5.8083612168199465\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "TRUE REWARD = 83.24426408004217\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 73.1993941811405\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 2.0584494295802447\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 70.80725777960456\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 18.182496720710063\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 15.599452033620265\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 21.233911067827616\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 95.07143064099162\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "TRUE REWARD = 86.61761457749351\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "TRUE REWARD = 60.11150117432088\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "TRUE REWARD = 37.454011884736246\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 96.99098521619943\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "TRUE REWARD = 59.86584841970366\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "True rewards: tensor([15.6019,  5.8084, 15.6019, 15.5995, 70.8073, 37.4540, 95.0714,  2.0584,\n",
      "        70.8073,  2.0584, 59.8658,  2.0584,  2.0584,  2.0584, 60.1115, 59.8658,\n",
      "        15.5995, 70.8073,  5.8084, 18.3405, 59.8658,  5.8084, 37.4540, 95.0714,\n",
      "        18.1825, 95.0714, 86.6176, 60.1115, 21.2339, 18.3405, 95.0714,  2.0584,\n",
      "        70.8073, 15.6019, 86.6176, 95.0714, 73.1994, 18.3405, 60.1115, 83.2443,\n",
      "        15.5995, 21.2339, 95.0714, 15.5995, 18.1825,  5.8084,  5.8084,  5.8084,\n",
      "         5.8084,  2.0584, 86.6176, 70.8073, 18.3405, 59.8658, 73.1994, 86.6176,\n",
      "        37.4540,  5.8084, 96.9910, 59.8658, 18.1825, 59.8658, 83.2443, 18.1825,\n",
      "        83.2443, 70.8073, 15.6019, 73.1994, 18.3405, 96.9910, 18.3405, 59.8658,\n",
      "        37.4540, 96.9910, 15.5995, 86.6176, 15.5995, 96.9910,  2.0584, 18.1825,\n",
      "        70.8073, 15.5995, 18.3405, 60.1115, 83.2443,  5.8084, 96.9910, 73.1994,\n",
      "        95.0714,  2.0584, 60.1115, 15.6019, 15.6019, 95.0714, 15.6019, 83.2443,\n",
      "        15.5995, 70.8073, 59.8658, 95.0714, 96.9910, 59.8658, 83.2443, 15.5995,\n",
      "        96.9910, 18.3405, 21.2339, 59.8658,  5.8084, 70.8073, 59.8658, 95.0714,\n",
      "        70.8073, 37.4540, 95.0714, 37.4540, 15.5995, 95.0714, 70.8073, 95.0714,\n",
      "        18.1825, 70.8073, 70.8073, 37.4540,  2.0584, 86.6176, 59.8658, 60.1115,\n",
      "        60.1115, 86.6176,  5.8084, 70.8073, 18.3405, 83.2443, 21.2339, 37.4540,\n",
      "        86.6176, 70.8073, 83.2443, 15.5995, 60.1115, 70.8073, 21.2339, 60.1115,\n",
      "        15.6019,  2.0584, 37.4540, 37.4540, 21.2339, 18.3405, 95.0714, 15.5995,\n",
      "        73.1994,  5.8084, 15.5995, 37.4540, 18.3405, 37.4540, 96.9910, 15.5995,\n",
      "         5.8084, 15.5995, 60.1115, 18.1825, 96.9910, 95.0714, 15.6019, 15.5995,\n",
      "        70.8073, 37.4540,  5.8084, 60.1115, 83.2443,  5.8084, 21.2339, 60.1115,\n",
      "        21.2339, 15.5995, 60.1115,  5.8084, 60.1115, 15.5995, 73.1994, 59.8658,\n",
      "        18.3405, 37.4540,  2.0584, 18.1825, 83.2443, 60.1115, 60.1115, 60.1115,\n",
      "        73.1994, 73.1994, 15.5995,  2.0584, 86.6176, 96.9910, 18.1825, 95.0714,\n",
      "        70.8073, 15.6019, 73.1994, 70.8073, 86.6176, 18.1825, 15.6019, 70.8073,\n",
      "         5.8084, 70.8073, 83.2443, 18.1825, 70.8073,  5.8084, 86.6176, 60.1115,\n",
      "        37.4540, 18.1825, 15.5995, 86.6176,  5.8084, 83.2443, 21.2339, 73.1994,\n",
      "        60.1115, 18.1825, 96.9910,  2.0584, 95.0714, 59.8658, 86.6176, 18.1825,\n",
      "        70.8073, 60.1115, 18.1825, 96.9910, 15.5995, 18.1825, 86.6176, 15.5995,\n",
      "        95.0714, 21.2339, 95.0714, 95.0714, 86.6176, 60.1115, 37.4540, 96.9910,\n",
      "        96.9910, 59.8658])\n",
      "Learned rewards: tensor([ 0.0295, -0.3113,  0.0295, -0.3942, -0.3175, -1.0240, -0.1517, -0.4570,\n",
      "        -0.3175, -0.4570, -0.8067, -0.4570, -0.4570, -0.4570, -0.5177, -0.8067,\n",
      "        -0.3942, -0.3175, -0.3113, -0.2719, -0.8067, -0.3113, -1.0240, -0.1517,\n",
      "        -0.2925, -0.1517, -0.2305, -0.5177, -0.3889, -0.2719, -0.1517, -0.4570,\n",
      "        -0.3175,  0.0295, -0.2305, -0.1517, -0.4889, -0.2719, -0.5177, -1.0218,\n",
      "        -0.3942, -0.3889, -0.1517, -0.3942, -0.2925, -0.3113, -0.3113, -0.3113,\n",
      "        -0.3113, -0.4570, -0.2305, -0.3175, -0.2719, -0.8067, -0.4889, -0.2305,\n",
      "        -1.0240, -0.3113, -0.0596, -0.8067, -0.2925, -0.8067, -1.0218, -0.2925,\n",
      "        -1.0218, -0.3175,  0.0295, -0.4889, -0.2719, -0.0596, -0.2719, -0.8067,\n",
      "        -1.0240, -0.0596, -0.3942, -0.2305, -0.3942, -0.0596, -0.4570, -0.2925,\n",
      "        -0.3175, -0.3942, -0.2719, -0.5177, -1.0218, -0.3113, -0.0596, -0.4889,\n",
      "        -0.1517, -0.4570, -0.5177,  0.0295,  0.0295, -0.1517,  0.0295, -1.0218,\n",
      "        -0.3942, -0.3175, -0.8067, -0.1517, -0.0596, -0.8067, -1.0218, -0.3942,\n",
      "        -0.0596, -0.2719, -0.3889, -0.8067, -0.3113, -0.3175, -0.8067, -0.1517,\n",
      "        -0.3175, -1.0240, -0.1517, -1.0240, -0.3942, -0.1517, -0.3175, -0.1517,\n",
      "        -0.2925, -0.3175, -0.3175, -1.0240, -0.4570, -0.2305, -0.8067, -0.5177,\n",
      "        -0.5177, -0.2305, -0.3113, -0.3175, -0.2719, -1.0218, -0.3889, -1.0240,\n",
      "        -0.2305, -0.3175, -1.0218, -0.3942, -0.5177, -0.3175, -0.3889, -0.5177,\n",
      "         0.0295, -0.4570, -1.0240, -1.0240, -0.3889, -0.2719, -0.1517, -0.3942,\n",
      "        -0.4889, -0.3113, -0.3942, -1.0240, -0.2719, -1.0240, -0.0596, -0.3942,\n",
      "        -0.3113, -0.3942, -0.5177, -0.2925, -0.0596, -0.1517,  0.0295, -0.3942,\n",
      "        -0.3175, -1.0240, -0.3113, -0.5177, -1.0218, -0.3113, -0.3889, -0.5177,\n",
      "        -0.3889, -0.3942, -0.5177, -0.3113, -0.5177, -0.3942, -0.4889, -0.8067,\n",
      "        -0.2719, -1.0240, -0.4570, -0.2925, -1.0218, -0.5177, -0.5177, -0.5177,\n",
      "        -0.4889, -0.4889, -0.3942, -0.4570, -0.2305, -0.0596, -0.2925, -0.1517,\n",
      "        -0.3175,  0.0295, -0.4889, -0.3175, -0.2305, -0.2925,  0.0295, -0.3175,\n",
      "        -0.3113, -0.3175, -1.0218, -0.2925, -0.3175, -0.3113, -0.2305, -0.5177,\n",
      "        -1.0240, -0.2925, -0.3942, -0.2305, -0.3113, -1.0218, -0.3889, -0.4889,\n",
      "        -0.5177, -0.2925, -0.0596, -0.4570, -0.1517, -0.8067, -0.2305, -0.2925,\n",
      "        -0.3175, -0.5177, -0.2925, -0.0596, -0.3942, -0.2925, -0.2305, -0.3942,\n",
      "        -0.1517, -0.3889, -0.1517, -0.1517, -0.2305, -0.5177, -1.0240, -0.0596,\n",
      "        -0.0596, -0.8067])\n"
     ]
    }
   ],
   "source": [
    "mse, mae = evaluate(venv, reward_net, weights, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding MSE and MAE over Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between true and learned rewards: 3446.799072265625\n",
      "MAE between true and learned rewards: 48.63444137573242\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE between true and learned rewards:\", mse)\n",
    "print(\"MAE between true and learned rewards:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBS = [ 2 15 11 14]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "OBS = [12 11  1 12]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.233911514282227\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.233911514282227\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.340450286865234\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "OBS = [6 6 3 2]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.340450286865234\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.2442626953125\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "OBS = [ 8 14 15 12]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "OBS = [ 2  2 13 12]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "OBS = [ 2 10 13  3]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.233911514282227\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.233911514282227\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.340450286865234\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "OBS = [ 4  5 15  4]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.340450286865234\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.233911514282227\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "OBS = [5 1 7 6]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.2442626953125\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.865848541259766\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.2442626953125\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.2442626953125\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.61761474609375\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "OBS = [10  0 10  2]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.340450286865234\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.233911514282227\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.340450286865234\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.0714340209961\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "OBS = [11 10 15  4]\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.0584495067596436\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.182497024536133\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.233911514282227\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.80725860595703\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.808361053466797\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.601863861083984\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 96.99098205566406\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.11149978637695\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 86.71761322021484\n",
      "LEARNED REWARD = -0.2305210828781128\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 21.333911895751953\n",
      "LEARNED REWARD = -0.3888707160949707\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.454010009765625\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 37.554012298583984\n",
      "LEARNED REWARD = -1.02402925491333\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.599452018737793\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.19939422607422\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 70.90725708007812\n",
      "LEARNED REWARD = -0.31745225191116333\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 73.29939270019531\n",
      "LEARNED REWARD = -0.4889352023601532\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 97.09098815917969\n",
      "LEARNED REWARD = -0.05955219268798828\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 83.3442611694336\n",
      "LEARNED REWARD = -1.0217804908752441\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.28249740600586\n",
      "LEARNED REWARD = -0.29250359535217285\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 2.158449411392212\n",
      "LEARNED REWARD = -0.45703357458114624\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 18.44045066833496\n",
      "LEARNED REWARD = -0.2718842029571533\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 60.21150207519531\n",
      "LEARNED REWARD = -0.5177268385887146\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 15.701864242553711\n",
      "LEARNED REWARD = 0.02954721450805664\n",
      "Processing environment 0:\n",
      "  TRUE_REWARD = 59.96584701538086\n",
      "LEARNED REWARD = -0.8066972494125366\n",
      "Processing environment 1:\n",
      "  TRUE_REWARD = 15.69945240020752\n",
      "LEARNED REWARD = -0.3942369520664215\n",
      "Processing environment 2:\n",
      "  TRUE_REWARD = 5.908361434936523\n",
      "LEARNED REWARD = -0.3113442659378052\n",
      "Processing environment 3:\n",
      "  TRUE_REWARD = 95.17143249511719\n",
      "LEARNED REWARD = -0.1516696661710739\n"
     ]
    }
   ],
   "source": [
    "def evaluate_policy_rewards(policy, env, reward_net, num_episodes=10):\n",
    "    true_rewards = []\n",
    "    learned_rewards = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        # Reset the environment and get the initial observation for all environments\n",
    "        obs = env.reset()  # VecEnv returns a batch of observations\n",
    "        print(f\"OBS = {obs}\")\n",
    "        \n",
    "        done = [False] * env.num_envs  # Initialize the done flags for all environments\n",
    "\n",
    "        while not any(done):  # Continue until all environments are done\n",
    "            actions = []\n",
    "            for i in range(env.num_envs):\n",
    "                # Get the action from the policy for each environment\n",
    "                action, _ = policy.predict(obs[i])  # Predict action based on each environment's observation\n",
    "                actions.append(action)  # Store the action for each environment\n",
    "\n",
    "            # print(f\"ACTIONS = {actions}\")\n",
    "            \n",
    "            # Step the vectorized environment with actions for all environments\n",
    "            next_obs, true_reward, done, info = env.step(actions)  # Step all environments at once\n",
    "\n",
    "            # print(f\"NEXT_OBS = {next_obs}\")\n",
    "            # print(f\"TRUE_REWARD = {true_reward}\")\n",
    "            # print(f\"DONE = {done}\")\n",
    "            # print(f\"INFO = {info}\")\n",
    "\n",
    "            # Process each environment's result separately\n",
    "            for i in range(env.num_envs):\n",
    "                print(f\"Processing environment {i}:\")\n",
    "                # print(f\"  OBS = {obs[i]}\")\n",
    "                # print(f\"  NEXT_OBS = {next_obs[i]}\")\n",
    "                print(f\"  TRUE_REWARD = {true_reward[i]}\")\n",
    "                # print(f\"  DONE = {done[i]}\")\n",
    "                # print(f\"  INFO = {info[i]}\")\n",
    "\n",
    "                # Append the true reward for the current environment\n",
    "                true_rewards.append(true_reward[i])\n",
    "\n",
    "                if isinstance(env.observation_space, spaces.Discrete):\n",
    "                    num_states = env.observation_space.n\n",
    "                    state_one_hot = np.zeros(num_states)\n",
    "                    state_one_hot[obs[i]] = 1\n",
    "                    state_tensor = th.FloatTensor(state_one_hot).unsqueeze(0)  \n",
    "                else:\n",
    "                    state_tensor = th.FloatTensor(obs[i]).unsqueeze(0)  \n",
    "\n",
    "                num_actions = env.action_space.n\n",
    "                action_one_hot = np.zeros(num_actions)\n",
    "                action_one_hot[actions[i]] = 1\n",
    "                action_tensor = th.FloatTensor(action_one_hot).unsqueeze(0)  \n",
    "\n",
    "                learned_reward = reward_net(state_tensor, action_tensor, None, None).item()\n",
    "                print(f\"LEARNED REWARD = {learned_reward}\")\n",
    "\n",
    "                learned_rewards.append(learned_reward)\n",
    "\n",
    "            # Move to the next observations for all environments\n",
    "            obs = next_obs\n",
    "\n",
    "    true_rewards_tensor = th.tensor(true_rewards, dtype=th.float32)\n",
    "    learned_rewards_tensor = th.tensor(learned_rewards, dtype=th.float32)\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    mse = th.mean((true_rewards_tensor - learned_rewards_tensor) ** 2).item()\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = th.mean(th.abs(true_rewards_tensor - learned_rewards_tensor)).item()\n",
    "\n",
    "    return mse, mae\n",
    "\n",
    "mse, mae = evaluate_policy_rewards(expert_policy, venv, reward_net, num_episodes=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between true and learned rewards: 3280.7822265625\n",
      "MAE between true and learned rewards: 46.88328552246094\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE between true and learned rewards:\", mse)\n",
    "print(\"MAE between true and learned rewards:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation sample some states and actions, and try running it through both true reward and learned reward (find MAE/MSE)\n",
    "\n",
    "want to also create a deterministic transition function with a NN\n",
    "\n",
    "rational set theory\n",
    "    - if you want to build a model to approximate something, there will be 10s of thousands with similar MSE and MAE\n",
    "    - add regularization\n",
    "        - longer you play less likely to quit\n",
    "        - more likely to purchase games\n",
    "    - using this we can reduce the model space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tobin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
