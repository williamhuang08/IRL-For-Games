{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gridworld.modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Box,Discrete\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgridworld\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent, Wall, Goal, State, Hole, Block\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gridworld.modules'"
     ]
    }
   ],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pygame as pg\n",
    "from collections import deque\n",
    "from gym.spaces import Box,Discrete\n",
    "from collections import defaultdict\n",
    "from gridworld.modules import Agent, Wall, Goal, State, Hole, Block\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os.path as osp\n",
    "import random\n",
    "from typing import Dict,List\n",
    "import gym.spaces as spaces\n",
    "import hydra\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import yaml\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from hydra.utils import instantiate as hydra_instantiate\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from rl_utils.common import (Evaluator, compress_dict, get_size_for_space,\n",
    "                             set_seed)\n",
    "from rl_utils.envs import create_vectorized_envs\n",
    "from rl_utils.logging import Logger\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from gym.utils import seeding\n",
    "from gym.envs.registration import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld(gym.Env):\n",
    "    def __init__(self, grid_size=(4, ), start_position=(0, 0), goal_position=(4, 4), obstacles=None):\n",
    "        super(GridWorld, self).__init__()\n",
    "        \n",
    "        # Initialize environment parameters\n",
    "        self.grid_size = grid_size\n",
    "        self.start_position = start_position\n",
    "        self.goal_position = goal_position\n",
    "        self.obstacles = obstacles if obstacles else []\n",
    "        \n",
    "        # Define action and observation spaces\n",
    "        # Actions: 0 = Up, 1 = Right, 2 = Down, 3 = Left\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # Observation: Agent's current position in the grid (x, y)\n",
    "        self.observation_space = spaces.Box(low=0, high=max(grid_size)-1, shape=(2,), dtype=np.int32)\n",
    "        \n",
    "        # Initialize agent's position\n",
    "        self.state = np.array(self.start_position)\n",
    "        \n",
    "        # Initialize the random seed\n",
    "        self.seed()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        # Seed the environment's random number generator\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the agent's position to the start\n",
    "        self.state = np.array(self.start_position)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Define movement directions\n",
    "        movement = {\n",
    "            0: (-1, 0),  # Up\n",
    "            1: (0, 1),   # Right\n",
    "            2: (1, 0),   # Down\n",
    "            3: (0, -1)   # Left\n",
    "        }\n",
    "        \n",
    "        # Calculate the new position\n",
    "        new_position = self.state + np.array(movement[action])\n",
    "        \n",
    "        # Check if the new position is within the grid bounds\n",
    "        if (0 <= new_position[0] < self.grid_size[0]) and (0 <= new_position[1] < self.grid_size[1]):\n",
    "            # Check if the new position is not an obstacle\n",
    "            if tuple(new_position) not in self.obstacles:\n",
    "                self.state = new_position\n",
    "        \n",
    "        # Check if the agent has reached the goal\n",
    "        done = np.array_equal(self.state, self.goal_position)\n",
    "        reward = 1 if done else -0.1  # Reward for reaching goal, penalty otherwise\n",
    "\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # Render the grid\n",
    "        grid = np.full(self.grid_size, ' ')\n",
    "        grid[self.goal_position] = 'G'  # Goal\n",
    "        for obs in self.obstacles:\n",
    "            grid[obs] = 'X'  # Obstacles\n",
    "        grid[tuple(self.state)] = 'A'  # Agent\n",
    "        print(\"\\n\".join([\"\".join(row) for row in grid]))\n",
    "        print()\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Sets the seed for numpy, python random, and pytorch.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchrl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_vectorized_envs\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimitation_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy_opt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Policy\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimitation_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy_opt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mppo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPO\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimitation_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy_opt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RolloutStorage\n",
      "File \u001b[0;32m~/Documents/Projects/Tobin 2024/Code/code/bc-irl-main/imitation_learning/policy_opt/policy.py:15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (FixedCategorical, FixedNormal, SimpleCNN,\n\u001b[1;32m     12\u001b[0m                              build_rnn_state_encoder)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (TensorDictModule, TensorDictSequential)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ActorValueOperator, ConvNet, ProbabilisticActor,\n\u001b[1;32m     16\u001b[0m                              ValueOperator)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_weights\u001b[39m(m, gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, nn\u001b[38;5;241m.\u001b[39mLinear):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchrl'"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import gym.spaces as spaces\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from hydra.utils import instantiate as hydra_instantiate\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from rl_utils.common import (Evaluator, compress_dict, get_size_for_space,\n",
    "                             set_seed)\n",
    "from rl_utils.envs import create_vectorized_envs\n",
    "from rl_utils.logging import Logger\n",
    "\n",
    "from imitation_learning.policy_opt.policy import Policy\n",
    "from imitation_learning.policy_opt.ppo import PPO\n",
    "from imitation_learning.policy_opt.storage import RolloutStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = yaml.load(open(\"/Users/williamhuang/Documents/Projects/Tobin 2024/Code/code/bc-irl-main/imitation_learning/config/default.yaml\", 'r'), Loader=yaml.SafeLoader)\n",
    "cfg = DictConfig(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import yaml\n",
    "from typing import List, Tuple, Dict\n",
    "from gymnasium.core import Env\n",
    "from omegaconf import DictConfig\n",
    "import gym\n",
    "import gym_minigrid as minigrid\n",
    "\n",
    "# Define the vectorized environment class\n",
    "class VectorizedEnv:\n",
    "    def __init__(self, envs: List[Env]):\n",
    "        self.envs = envs\n",
    "        self.num_envs = len(self.envs)\n",
    "        self.observation_space = self.envs[0].observation_space\n",
    "        self.action_space = self.envs[0].action_space\n",
    "\n",
    "    def reset(self):\n",
    "        observations = [env.reset()[0] for env in self.envs]\n",
    "        return torch.tensor(observations, dtype=torch.float32)\n",
    "\n",
    "    def step(self, actions) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[Dict]]:\n",
    "        steps = [env.step(actions[i]) for i, env in enumerate(self.envs)]\n",
    "        observations = torch.tensor([step[0] for step in steps], dtype=torch.float32)\n",
    "        rewards = torch.tensor([step[1] for step in steps], dtype=torch.float32)\n",
    "        dones = torch.tensor([step[2] for step in steps], dtype=torch.bool)\n",
    "        infos = [step[3] for step in steps]\n",
    "        return observations, rewards, dones, infos\n",
    "\n",
    "# Function to set random seeds for reproducibility\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Load configuration from YAML file\n",
    "with open(\"bc-irl-mouse.yaml\", 'r') as file:\n",
    "    cfg_dict = yaml.safe_load(file)\n",
    "cfg = DictConfig(cfg_dict)\n",
    "\n",
    "# Set seed and device\n",
    "set_seed(cfg.seed)\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "# Function to create a single environment instance\n",
    "def make_env(seed=None):\n",
    "    def _init():\n",
    "        env = gym.make(\"MiniGrid-Empty-5x5-v0\")\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Create a list of environment instances with unique seeds\n",
    "num_envs = cfg.num_envs\n",
    "envs = [make_env(cfg.seed + i)() for i in range(num_envs)]\n",
    "\n",
    "# Instantiate the vectorized environment\n",
    "vec_env = VectorizedEnv(envs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_utils.common import (Evaluator, compress_dict, get_size_for_space,\n",
    "                             set_seed)\n",
    "import gym.spaces as spaces\n",
    "\n",
    "steps_per_update = cfg.num_steps * cfg.num_envs\n",
    "num_updates = int(cfg.num_env_steps) // steps_per_update\n",
    "\n",
    "cfg.obs_shape = vec_env.observation_space['image'].shape\n",
    "cfg.action_dim = get_size_for_space(vec_env.action_space)\n",
    "cfg.action_is_discrete = isinstance(cfg.action_dim, spaces.Discrete)\n",
    "cfg.total_num_updates = num_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('direction': Discrete(4), 'image': Box(0, 255, (7, 7, 3), uint8), 'mission': MissionSpace(<function EmptyEnv.__init__.<locals>.<lambda> at 0x12afdd790>, None))\n"
     ]
    }
   ],
   "source": [
    "print(vec_env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 3)\n",
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(vec_env.observation_space['image'].shape)\n",
    "print(vec_env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning full prefix 118-3-d6uqDM\n"
     ]
    },
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'imitation_learning.policy_opt.policy.Policy':\nTypeError(\"__init__() got an unexpected keyword argument 'num_envs'\")\nfull_key: policy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/bcirl/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:86\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'num_envs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m logger: Logger \u001b[38;5;241m=\u001b[39m hydra_instantiate(cfg\u001b[38;5;241m.\u001b[39mlogger, full_cfg\u001b[38;5;241m=\u001b[39mcfg)\n\u001b[1;32m      7\u001b[0m storage: RolloutStorage \u001b[38;5;241m=\u001b[39m hydra_instantiate(cfg\u001b[38;5;241m.\u001b[39mstorage, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 8\u001b[0m policy: Policy \u001b[38;5;241m=\u001b[39m \u001b[43mhydra_instantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m policy \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcirl/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:218\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     _convert_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mCONVERT, ConvertMode\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[1;32m    216\u001b[0m     _partial_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mPARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_partial_\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_list(config):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     config_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcirl/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:331\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 value \u001b[38;5;241m=\u001b[39m instantiate_node(\n\u001b[1;32m    327\u001b[0m                     value, convert\u001b[38;5;241m=\u001b[39mconvert, recursive\u001b[38;5;241m=\u001b[39mrecursive\n\u001b[1;32m    328\u001b[0m                 )\n\u001b[1;32m    329\u001b[0m             kwargs[key] \u001b[38;5;241m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured, instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert \u001b[38;5;241m==\u001b[39m ConvertMode\u001b[38;5;241m.\u001b[39mALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    335\u001b[0m         convert \u001b[38;5;241m==\u001b[39m ConvertMode\u001b[38;5;241m.\u001b[39mPARTIAL \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mobject_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/bcirl/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:91\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[1;32m     90\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'imitation_learning.policy_opt.policy.Policy':\nTypeError(\"__init__() got an unexpected keyword argument 'num_envs'\")\nfull_key: policy"
     ]
    }
   ],
   "source": [
    "from imitation_learning.policy_opt.policy import Policy\n",
    "from imitation_learning.policy_opt.ppo import PPO\n",
    "from imitation_learning.policy_opt.storage import RolloutStorage\n",
    "\n",
    "logger: Logger = hydra_instantiate(cfg.logger, full_cfg=cfg)\n",
    "\n",
    "storage: RolloutStorage = hydra_instantiate(cfg.storage, device=device)\n",
    "policy: Policy = hydra_instantiate(cfg.policy)\n",
    "policy = policy.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcirl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
